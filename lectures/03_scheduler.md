<!--

author:   Andreas Heil

email:    andreas.heil@hs-heilbronn.de

version:  0.1

language: de

narrator: DE German Male

tags: betriebssysteme, lecture, scheduler

comment:  

-->

# Virtualisierung

<!-- data-type="none" -->
| Parameter | Kursinformationen |
| --- | --- |
| **Veranstaltung:** | `262007 DevOps`|
| **Semester** | `SEB2` |
| **Hochschule:** | `Hochschule Heilbronn` |
| **Inhalte:** | `Scheduler` |
| Startseite | [https://liascript.github.io/course/?https://raw.githubusercontent.com/aheil/os/master/README.md#1](https://liascript.github.io/course/?https://raw.githubusercontent.com/aheil/os/master/README.md#1) | 
| **Link auf den GitHub:** | [https://github.com/aheil/os/blob/main/lectures/03_scheduler.md](https://github.com/aheil/os/blob/main/lectures/03_scheduler.md) |
| **Autoren** | @author |

## Lernziele und Kompetenzen

* **Verstehen** wie Prozesse im Betriebssystem gesteuert werden
* **Verstehen** welche Probleme bei der direkten Ausf√ºhrung von Prozessen auf der CPU entstehen und wie dem im Betriebssystem begegnet wird
* Grundlagen der Scheduling-Mechanismen **kennen lernen** 
* **Verstehen** wie Prozesse von Betriebssystemen geschedult werden k√∂nnen

## Direct Execution 

**Problem**

Bisher haben wir gelernt, dass es Prozesse gibt, diese irgendwie gestartet werden k√∂nnen.

Das Betriebssystem l√§dt also ein Programm, l√§dt alle Register und startet den Prozess... 

Der Prozess bekommt vollen Zugriff auf alle Ressourcen und l√§uft direkt auf der CPU, bis der Prozess die Kontrolle wieder an das Betriebssystem abgibt (engl. direct execution). 

* **Frage 1:** Wie stellen wir sicher, dass der Prozess nichts ¬ªVerbotenes¬´ tut?

* **Frage 2:** Die direkte Ausf√ºhrung des Prozesses auf der CPU (engl. direct execution) ist zwar schnell, aber was passiert nun, wenn der Prozess eingeschr√§nkte Aktionen durchf√ºhren will (z.B. mehr Speicher, I/O-Operation etc.)?

* **Frage 3:** Und wie stellen wir √ºberhaupt sicher, dass der Prozess die Kontrolle wieder abgibt? Solange der Prozess ausgef√ºhrt wird, hat das Betriebssystem ja keine Kontrolle √ºber die CPU... ü§î

{{1}}
************************************

**L√∂sungsidee**

Programme laufen im sog. **¬ªUser Mode Linux¬´** oder allgemein **¬ªUser Mode¬´**. 

* Es wird eingeschr√§nkt, was das Programm ¬ªtun¬´ kann
* Z.b. werden I/O-Operationen eingeschr√§nkt
* Wenn ein Programm versucht etwas unerlaubtes auszuf√ºhren wird eine ¬ªException¬´ im Prozessor erzeugt (das hei√üt tats√§chlich so, hat aber nichts z.B. mit Java Exceptions zu tun)

Der Gegensatz: **¬ªKernel Mode¬´**

* Hier sind alle Operationen, auch bzw. insbesondere I/O-Operationen erlaubt


************************************

## SysCall

Wenn ein Programm im *User Mode* etwas ausf√ºhren m√∂chte, das eigentlich untersagt ist, f√ºhrt es einen sog. ¬ªSystem Call¬´ oder kurz ¬ªSyscall¬´ aus.

* System Calls werden von allen modernen Betriebssystemen angeboten
* POSIX-Systeme (Portable Operating System Interface[^1]) bieten mehrere hundert solcher System Calls an 

[^1]: https://standards.ieee.org/project/1003_1.html#Standard



### System Call Ablauf

Das Programm... 

* F√ºhrt ein sog. Trap-Instruktion aus
* Springt in Kernel und startet im privilegierten Modus (Kernel Modus)
* F√ºhrt die Operationen aus, die im ¬ªSystem Call Handler¬´ hinterlegt sind
* F√ºhrt eine sog. Return-From-Trap-Instruktion aus
* Kehrt in den User Mode zur√ºck

************************************

{{1}}
************************************

**Vorsicht**

Die Hardware muss darauf achten ‚Äûgen√ºgend Bestandteile vom Programm bestehen zu lassen‚Äú, so dass es sp√§ter wieder ausgef√ºhrt werden kann.

Am Beispiel des x86: 

Hier werden...

* Program Counter, Flags und weitere Register in einen sog. Per-Process-Kernel-Stack ¬ªgepusht¬´ (Datenstruktur Stack klar? Ggf. Exkurs am Ende)
* Bei der Return-From-Trap-Instruktion werden diese wieder vom Stack geladen
* Danach kann das Programm wieder im User Mode ausgef√ºhrt werden

Dieses Vorgehen wird von Betriebssystem zu Betriebssystem zwar unterschiedlich gehandhabt, ist im Grundsatz aber immer √§hnlich

************************************

{{2}}
************************************

**Nochmal Vorsicht**

**Frage:** Woher wei√ü das OS, welcher Code f√ºr System Calls ausgef√ºhrt werden soll?

Das Programm kann ja kein Speicherbereich angeben

Grunds√§tzlich w√§re das auch eine sehr schlechte Idee‚Ä¶ Das ist schon klar warum , oder?

************************************

{{3}}
************************************

**L√∂sung: Trap Table ** 

* Es wird eine sog. ¬ªTrap Table¬´ zur Boot-Zeit erstellt
* Beim Booten ist das System immer im Kernel Mode
* Das Betriebssystem kann der Hardware somit sagen, welcher Code bei welchem Ereignis ausgef√ºhrt wird 
* Das Betriebssystem informiert die Hardware √ºber diese sog. Trap Handlers oder System Call Handlers

> Nur mal so... Was k√∂nnte man denn machen, wenn man eine eigene Trap Table installieren k√∂nnte? ü§î

************************************

### Zusammenfassung

* Prozesse direkt (d.h. ohne Kontrolle) auf der Hardware auszuf√ºhren, ist keine gute Idee 
* Prozesse werden im User Mode ausgef√ºhrt und sind eingeschr√§nkt was bestimmte Aktionen angeht 
* Mittels System Calls kann ein Prozess spezielle Aktionen ausf√ºhren (lassen), die jedoch vom Betriebssystem kontrolliert werden
* Eine Trap Table enth√§lt die Information dar√ºber, wo der Code steht, der durch ein System Call ausgef√ºhrt wird 
* Trap Tables werden zur Boot-Zeit (im Kernel Modus) erzeugt

## Scheduler 

Der Scheduler regelt nun, welcher Prozess laufend darf, und wann der n√§chste Prozess dran ist, wie genau macht der Scheduler das jedoch? Hierf√ºr wird ein Regelwerk ben√∂tigt.

{{1}}
************************************

**Scheduling Policy**

* Die ¬ªScheduling Policy¬´ (also das Regelwerk) h√§ngt vorrangig vom ¬ªWorkload¬´ der Prozesse ab
* Zur Vereinfachung werden zun√§chst folgende (absolut unrealistische) Annahmen getroffen:

  * Jeder Job l√§uft gleich lang
  * Alle Jobs treffen zur gleichen Zeit ein
  * Einmal gestartet, l√§uft ein Job bis er beendet ist
  * Alle Jobs verwenden ausschlie√ülich die CPU
  * Laufzeit (engl. runtime) eines jeden Jobs ist bekannt

************************************

{{2}}
************************************

Um die Scheduling Policy zu bewerten ben√∂tigen wir eine Kennzahl, eine sog Metrik:

* Hinweis: Metriken werden im 3. Semester in SEKS vertieft 
* F√ºr heute gen√ºgt: Metrik = einfach um etwas zu messen
* F√ºr uns: zun√§chst nur eine Metrik

**Scheduler Metriken: Turnaround-Zeit**

$$
T_{turnaround}=T_{completion}-T_{arrival}
$$

Aufgrund unserer vorherigen Annahmen gelten

* Alle Jobs kommen zum  gleichen Zeitpunkt an: $T_{arrival} = 0$
* Somit gilt: $T_{turnaround}=T_{completion}$

************************************

### First In, First Out 

First in, First out (abk. FIFO) oder manchmal auch First Come, First Serve (abk. FCFS)

{{1}}
************************************

* Einfach und daher auch einfach zu implementieren

* Beispiel

  * Jobs A, B und C kommen kurz nacheinander an
  * Jeder Job hat eine Laufzeit von 10 Sekunden
  * Was ist die durchschnittliche Turnaround-Zeit?
  * $\frac{10+20+30}{3}=20$

![](../img/os.03.fifo.png)

************************************

{{2}}
************************************

* Heben wir jetzt die erste Annahme auf

  * Zur Erinnerung: Jeder Job l√§uft gleich lang
  * Ab sofort: Jeder Job l√§uft eben nicht mehr gleich lang
  * Gibt es einen Workload, der FIFO ¬ªalt aussehen l√§sst¬´?
  * $\frac{100+110+120}{3}=110$

![](../img/os.03.fifo_bad.png)

************************************

{{3}}
************************************

**Convoy Effect (dt. Konvoieffekt)**

* Kennt jeder
* Mehrere Kunden mit wenigen Waren warten hinter einem einzigen Kunden mit vielen Waren 
* Nur eine Supermarktkasse offen... üò§

![](../img/os.03.convoy.jpg)[^2]

[^2]: Photo by Paul Townsend, licensed under Attribution-ShareAlike 2.0 Generic (CC BY-SA 2.0)


************************************#

### Shortes Job First

* Shortest Job first (Abk. SJF)
* Beschreibt die Policy recht treffend 

    * F√ºhrt den k√ºrzesten Job aus, dann den zweit k√ºrzesten etc.

* Beispiel von zuvor

    * SJF reduziert Turnaround-Zeit von 110 auf 50 

* $\frac{10+20+120}{3}=50$

![](../img/os.03.sjf.png)

{{1}}
************************************

**Problem bei SJF**

* L√∂sen wir ab jetzt die Restriktion, dass alle Jobs zum selben Zeitpunkt eintreffen
* Beispiel: A trifft bei $ùë°=0$, B und C bei $ùë° = 10$ ein
* Turnaround-Zeit hat sich hierdurch verdoppelt
* $\frac{100+(110-10)+(120-10)}{3}=103,33$

![](../img/os.03.sjf_bad.png)

************************************

### Shortest Time-to-Completion First

* Shortest Time-to-Completion First (STCF)

* SJF ist non-preemptive ‚ñ∂ versuchen wir es preemptive


{{1}}
************************************

**Exkurs: Non-Preemptive vs. Preemptive** 
_
* Non-Preemptive 

  * Stammt aus den Zeiten von sog. Batch-Systemen
  * Jeder Job wurde zu Ende gerechnet, bevor √ºberhaupt in Erw√§gung gezogen wurde einen anderen Job zu starten 

* Preemptive

  * Alle modernen Betriebssysteme sind ¬ªpreemptive¬´
  * Jederzeit gewillt einen Job zu stoppen und einen anderen daf√ºr zu starten
  * Nutzen den zuvor behandelten Context Switch

************************************

{{2}}
************************************

* L√∂sen wir nun die Restriktion, dass alle Jobs bis zum Ende durchlaufen 
* Jedes Mal wenn ein Job eintrifft, wird derjenige der die geringste Restlaufzeit

* **Achtung!** Das geht nur wegen unserer letzten noch bestehenden Annahme: Die (Rest-)Laufzeit ist bekannt! 

* $\frac{(120-0)+(20-10)+(30-10)}{3}=50$

![](../img/os.03.stcf.png)[^3]

[^3]: Bild von Gerd Altmann auf Pixabay

************************************

{{3}}
************************************

**Problem mit STCF**

* Benutzer wartet bis Job A (z.B. Aktualisierung in Excel o.√§.) fertig ist
* Nun kommt die Hausaufgabe vom letzten Mal ins Spiel: Sie erinnern sich an den Unterschied zwischen Foreground- und Background-Jobs?  
* Was ist denn, wenn andauernd neue k√ºrzere Jobs eintreffen, die keine Benutzereingabe erfordern‚Ä¶ ü•±

![](../img/os.03.wait.jpg)

************************************

### Round Robin

Um eine weitere Scheduling Policy zu pr√ºfen ben√∂tigen wir eine weitere Metrik. 

{{1}}
************************************

**Scheduler Metriken: Antwortzeit**

* Zweite Metrik f√ºr heute: Antwortzeit (eng. response time)
* Dauer vom Zeitpunkt an dem Job eintrifft bis er das erste Mal ¬ªgescheduled¬´ wird
* $\frac{0 + 5 + 10}{3}=5$

$$
T_{response}=T_{firstrun}-T_{arrival}
$$

![](../img/os.03.sjf_responsetime.png)

************************************

{{2}}
************************************
**Round Robin**

* Grundprinzip von Round Robin (RR): Jeder Job wird nur f√ºr eine bestimmte Zeitspanne (engl. time slice) ausgef√ºhrt 
* Zeitscheibe ist ein Vielfaches vom Timer Interrupt (d.h. bei einem Timer Interrupt von 10ms ein Vielfaches von 10)
* Durchschnittliche Antwortzeit im Vergleich zu SJF (vorherige Folie) ist 1
* $\frac{0 + 1 + 2}{3}=1$

![](../img/os.03.rr_responsetime.png)

************************************

{{3}}
************************************

* Der Context Switch kostet Ressourcen
* D.h. wie lange m√ºssten die Time Slices sein, dass sich ein Context Switch √ºberhaupt lohnt?
* F√ºr Antwortzeit hervorragend geeignet, f√ºr Turnaround-Zeit √ºberhaupt nicht
* Round Robin zieht Ausf√ºhrungsdauer in die L√§nge, in manchen F√§llen ist die Ausf√ºhrung sogar schlechter als FIFO  
* Allgemein l√§sst sich festhalten: Jede Policy die fair ist, d.h. die CPU auf Prozesse aufteilt, f√ºhrt zu einem schlechten Ergebnis in Bezug auf Turnaround-Zeit 

************************************

