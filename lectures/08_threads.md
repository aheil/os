<!--

author:   Andreas Heil

email:    andreas.heil@hs-heilbronn.de

version:  0.1

language: de

narrator: DE German Male

tags: betriebssysteme, lecture, threads

comment:  

-->


# Threads

<!-- data-type="none" -->
| Parameter | Kursinformationen |
| --- | --- |
| **Veranstaltung:** | `262007 Betriebssysteme`|
| **Semester** | `SEB2` |
| **Hochschule:** | `Hochschule Heilbronn` |
| **Inhalte:** | `Threads` |
| Startseite | [https://liascript.github.io/course/?https://raw.githubusercontent.com/aheil/os/master/README.md#1](https://liascript.github.io/course/?https://raw.githubusercontent.com/aheil/os/master/README.md#1) | 
| **Link auf den GitHub:** | [https://github.com/aheil/os/blob/main/lectures/08_threads.md](https://github.com/aheil/os/blob/main/lectures/08_threads.md) |
| **Autoren** | @author |



## Lernziele 

- Unterschied zwischen Prozessen und Threads **kennen lernen** 
- Thread-API in C **nutzen k√∂nnen**

## Was sind Threads

**Wiederholung** 

* Bisher gelernt 

  * Virtualisierung einer CPU ‚Äì also mit ¬ªScheduling¬´ den Anschein erwecken, als g√§be es viele CPUs
  * Virtualisierung von Speicher ‚Äì also mittels ¬ªAdressr√§umen¬´ den Anschein erwecken, als h√§tte jedes Programm seinen ganz eigenen Speicher
  * Dabei galt implizit immer die Annahme, dass ein Prozess aus einem einzigen Ausf√ºhrungsstrang besteht

**Was sind Threads?**

* Anstelle nur eines Ausf√ºhrungsstrangs besitzen ¬ªmulti-threaded¬´ Programme mehrere Ausf√ºhrungsstr√§nge 
* Jeder dieser Ausf√ºhrungsstr√§nge (engl. thread) kann grunds√§tzlich wie ein Prozess verstanden werden
* Ein wichtiger Unterschied: W√§hrend jeder Prozess seinen ganz eigenen Adressraum besitzt, teilen sich Threads einen Adressraum und k√∂nnen auf dieselben Daten zugreifen

**Eigenschaften von Threads**

* Threads werden grunds√§tzlich wie Prozesse behandelt

  * Ben√∂tigen einen Programm Counter (PC) f√ºr die n√§chste Instruktion 
  * Haben eigene Register 
  * Laufen zwei Threads auf einer CPU, muss ein Context-Switch stattfinden
  * F√ºr den Context Switch wird ein *Thread Control Block* (TCB) analog zum Process Control Block (PCB) ben√∂tigt
  * Wichtiger Unterschied: Der Adressraum bleibt beim Context-Switch von Threads der gleiche

  
**Multi-Thread-Adressr√§ume**

Threads laufen unabh√§ngig, rufen eigene Routinen mit eigenen lokalen Variablen und R√ºcksprungadressen auf und ben√∂tigen daher dedizierte Stacks (engl. thread-local storage)

![](../img/os.08.multi_thread_address_space.png)


**Warum √ºberhaupt Threads verwenden?** 

**Offensichtlich:** Parallelisierung, sobald mehrere CPUs bereitstehen, k√∂nnen Aufgaben gleichzeitig durchgef√ºhrt werden

**Etwas subtiler:** W√ºrde ein Prozess aufgrund einer I/O-Operation geblockt werden, k√∂nnte ein weitere Thread im Prozess weiterlaufen und somit das blockieren des Prozesses vermeiden 

**Vorteil:** Threads greifen auf dieselben Daten innerhalb eines Prozesses zu. 

**Threads und Determinismus**

* Threads laufen nicht deterministisch, da Routinen im Thread unabh√§ngig vom Aufrufer laufen
* Was dann tats√§chlich l√§uft wird durch den Scheduler gesteuert 
* Problem versch√§rft sich noch, da Threads auf dieselben Daten zugreifen 

Konsequenz: Nicht-deterministische Programml√§ufe und Ergebnisse 

* OSTEP Kapitel 26.2 zum Erzeugen von Threads (in C)

## Scheduling Beispiel

**Hier: Erh√∂hen eines Counters um 1** 

* Variable f√ºr Counter liegt bei Adresse 0x8049a1c
* Wert der Variable wird in Register eax geladen (Zeile 1)
* Wert wird um 1 erh√∂ht  (Zeile 2)
* Neuer Wert wird aus Register zur√ºck an Andresse 0x8049a1c geschrieben


```assembler
mov 0x8049a1c, %eax
add $0x1, %eax
mov %eax, 0x8049a1c
```

**Annahme: Es gbit twei Threads, T1 und T2**

* T1 f√ºhrt den Code aus und erh√∂ht den Wert (z.B. 50) um 1 
* In Register eax steht nun 51
* Jetzt: Timer Interrupt, Betriebssystem speichert T1
  * Programm Counter 
  * Register einschlie√ülich eax 
* Nun wird T2 ausgef√ºhrt
* T2 l√§dt den Wert von 0x8049a1c 
* In eax steht nun 50 (Jeder Thread hat seine eigenen virtualisierten Register!!!1)
* eax wird erh√∂ht und zur√ºckgeschrieben 
* Jetzt findet nochmal ein Context-Switch statt und T1 wird wieder ausgef√ºhrt
* Alle Register werden geladen 
* In eax steht nun 51 
* T1 f√ºhrt nun noch Zeile 3 aus und schreibt 51 an 0x8049a1c
* Was sollte aber eigentlich in unserer Variable stehen? 

‚û° OSTEP Kapitel 26.3 f√ºr detaillierten Trace des Ablaufs

## Race Conditions 

* Ergebnis abh√§ngig vom Timing bei der Ausf√ºhrung von Code: Race Condition 
* F√ºhrt zu einem nicht-deterministischen Programmfehler, der in der Regel schwer zu finden ist (Ergebnis hei√üt auf engl. indeterminate)
* Code, der die Race Condition ausl√∂sen kann wird kritischer Abschnitt (engl. critical section) genannt
* Greift auf eine gemeinsame Variable (engl. shared variable) bzw. gemeinsame Ressource (engl. shared resource). 
* Durch wechselseitigen Ausschluss (engl. mutual exclusion) wird erreicht, dass wenn sich ein Thread in einem kritischen Abschnitt  befindet, kein anderer Thread auf diesen Code zugreifen kann‚Ä¶ 
* Aber wie?

## Thread API

Fragestellung: Welche Schnittstellen muss das Betriebssystem bereitstellen, um Threads zu erstellen und zu kontrollieren?

* Am Beispiel von POSIX (Portable Operating System Interface) Systemen:

  * Ein Thread erzeugen
  * Auf einen Thread warten
  * Locks = Ausschluss aus kritischem Abschnitt 
  * Condition Variable (dt. Monitor = Synchronisationsmechanismus)

4 Argumente erforderlich: `thread`, `attr`, `start routine`, `arg`

```c
#include <pthread.h>
int pthread_create(pthread_t *thread,
                   const pthread_attr_t *attr,
                   void *(*start_routine)(void*),
                   void *arg); 
```

* `thread`

  * Pointer auf Struktur vom Typ `pthread_t`, wird genutzt um mit dem Thread zu interagieren 

* `attr`

  * Spezifiziert die Attribute des Threads (Gr√∂√üe d. Stacks, Scheduling Priorit√§t etc.) 

* `start_routine`

  * Function Pointer auf Routine, die vom Thread ausgef√ºhrt werden soll

* `arg`

  * Argument, das an den Anfang des Threads √ºbergeben wird

**Auf einen Thread warten**

```c
int pthread_join(pthread_t thread, void **value_ptr);
```

* `pthread_t`

  * Spezifiziert den Thread, auf den gestartet wird 

* `value_ptr`

  * Zeiger auf den R√ºckgabewert der Routine 

* Einen Thread mittels `pthread_create` zu erzeugen und direkt danach mittels `pthread_join` auf dessen Beendigung zu warten ist nat√ºrlich nicht sonderlich sinnvoll

* In diesem Fall ist ein einfacher Prozeduraufruf einfacher.

* Wenn der Thread jedoch gestartet wird, und erst im sp√§teren Verlauf des Programms auf seine Beendigung gewartet wird, macht es wieder Sinn

![](../img/os.08.thread.png)

## Locks

* Funktionen f√ºr den gegenseitigen Ausschluss
* **Mutex:** Mutual Exclusion Object 

```c
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_lock(&lock); 
x = x + 1; // critical section
pthread_mutex_unlock(&lock);
```

**Wie funktioniert ein Mutex?**

* Kritischer Abschnitt kann nur betreten werden, wenn man (der Code) in Besitz des Mutex ist
* Beispiel hier: `pthread_mutex_loc` setzt das Mutex, und kein anderer Thread (mit dem gleichen Code) kann diesen Code-Abschnitt betreten, bevor `pthread_mutex_unlock` aufgerufen wurde
* Wie wird das erreicht? 

  * Ist der Lock gesetzt, kehrt die Routine `pthread_mutex_lock` erst zur√ºck, nachdem das Mutex freigegeben wurde

**Condition Variables** 

Verst√§ndigung zwischen Threads

* z.B. ein Thread wartet auf etwas von einem anderen Thread  
* `pthread_cond_wait` l√§sst den Thread warten, bis er das entsprechende Signal bekommt, dass er weitermachen kann

```c
int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);
int pthread_cond_signal(pthread_cond_t *cond);
```

**Zusammenfassung**

* Durch das Aufrufen einer `lock`-Routine wird versucht Zugriff auf ein ein Lock, also eine Art Token zu erhalten, die das alleinige Ausf√ºhrungsrecht eines kritischen Abschnitts sicherstellt 
* Ruft jemand anderes nun `lock` auf, kehrt diese Methode solange nicht zur√ºck, wie das Lock nicht freigegeben wurde
* Erst wenn der urspr√ºngliche Aufrufer durch `unlock` das Lock wieder frei gibt, kehrt eine der bisher aufgerufene `lock`-Routinen zur√ºck und l√§sst die Ausf√ºhrung des kritischen Abschnitts zu

**Anforderungen an ein Lock** 

* **Mutual Exclusion:** Locks m√ºssen gegenseitigen Ausschluss erm√∂glichen
* **Fairness:** Hat jeder Thread eine faire Chance das Lock zu erhalten, sobald es wieder freigegeben wird? Anders ausgedr√ºckt: Es muss vermieden werden, dass ein Thread verhungert (engl. starve), wenn er ‚Äûewig‚Äú auf das Lock wartet
* **Overhead:** H√§lt sich der Aufwand f√ºr einen einzelnen Thread in Grenzen, um das Lock zu erhalten und wieder freizugeben? Wie verh√§lt es sich mit der Performance, wenn es viele Threads und ggf. mehrere CPUs gibt?

### Ansatz 1: Interrupts deaktivieren

Durch Ausschalten der Interrupts, wird Code in einem kritischen Abschnitt nicht mehr unterbrochen

```c
void lock() {
  DisableInterrupts();
}
void unlock() {
  EnableInterrupts();
}
```

**Pro und Contra deaktivierte Interrupts** 

Vorteil:

* Einfach

Nachteil(e):

* Privilegierte Operation k√∂nnte ggf. missbraucht werden, indem am Anfang vom ganzen Programm `lock und erst am Ende `` unlock` aufgerufen wird
* Funktioniert nicht auf Multi-CPU-Systemen
* Wird, wenn √ºberhaupt, nur vom Betriebssystem intern genutzt, um auf eigene Datenstrukturen zuzugreifen oder um ung√ºnstige Interrupt-Situationen vorzubeugen

### Ansatz 2: Einfache Variable 

Weshalb kann die Verwendung einer einfachen Variablen als Lock nicht gen√ºgen?

Zur Erinnerung: Im POSIX-System verwenden wir auch eine Variable in Kombination mit `lock`- und `unlock`-Routinen. Wie funktioniert das? 

Grundidee:
* Einfache Variable (ein Flag) als Lock nutzen
* Aufruf von `lock` testet ob Flag == 1 ist, falls nicht wird dieses auf 1 gesetzt und Thread hat jetzt das Lock 
* Ruft nun ein zweiter Thread `lock` auf, wartet er solange bis das Flag wieder 0 ist

![](../img/os.08.simple_lock.de.png)

**Probleme**

* **Problem 1 (Korrektheit):** Durch ung√ºnstige Context-Switches schaffen es beide Threads nun zu laufen, da beide Threads das Flag auf 1 setzen konnten
* **Problem 2 (Performance):** W√§hrend ein Thread auf das Lock wartet, pr√ºft er st√§ndig die Variable und verschwendet Rechenzeit des anderen Prozesses z.B. durch Context-Switch, Speicherzugriff, etc. (eng. spin-waiting)

### Ansatz 3: Spin Locks mit Test-and-Set 

* Hardware-Unterst√ºtzung bereits in den 1960ern, die heute noch zum Einsatz kommt 
* Test-and-Set bzw. Atomic Exchange 
* Liefert den ¬ªalten¬´ Wert an der Adresse von `old_ptr`
* Setzt gleichzeitig den Wert an `*old_ptr` auf den Inhalt von new
* Wichtig: Diese Operationen werden atomar aufgerufen! 

```c
int TestAndSet(int *old_ptr, int new) {
  int old = *old_ptr; // fetch old value at old_ptr 3 
  *old_ptr = new; // store ‚Äônew‚Äô into old_ptr
  return old; // return the old value
}
```

**Es funktioniert weil...** 

**Szenario 1**

* Annahme, Thread ruft `lock` auf und kein anderer Thread h√§lt das Lock (flag==0)
* `TestAndSet` liefert 0, also wird der aufrufende Thread nicht weite pr√ºfen (spinning)
* Das Flag wird au√üerdem auf 1 gesetzt (atomar!), d.h. kein anderer Thread kann das Lock erhalten 
* Ist der Thread fertig, ruft er `unlock` auf und das Flag wird wieder auf 0 gesetzt

**Szenario 2**

* Annahme, Ein anderer Thread h√§lt das Lock (flag==1)
* `TestAndSet` liefert 1, also wird der aufrufende Thread nicht weite pr√ºfen (spinning)
* Das Flag wird au√üerdem auf 1 gesetzt (atomar!), das ist aber nicht schlimm
* Solange der andere Thread das Lock besitzt, liefert `TestAndSet` immer 1

**Spinning Lock**

* Wir haben das erste funktionierende Lock gebaut 
* Spin Lock: Einfachste Variante, dreht sich (engl. to spin) solang unter der Verwendung von CPU Cycles bis das Lock verf√ºgbar wird
* Ben√∂tigt einen Preemtive Scheduler (Sie erinnern sich!?), der Threads via Timer unterbricht, damit ein anderer Thread laufen kann ÔÉ† ohne Preemtive Scheduling machen Spin Locks auf Systemen mit nur einer CPU keinen Sinn, da der Thread sonst nie die CPU freigeben w√ºrde 

> In x86 z.B. via `xchg` realisiert (x86 Instruction Set Reference[^1]): ‚Äû... This instruction is useful for implementing semaphores or similar data structures for process synchronization.‚Äù

**Spin Locks: Kurze Betrachtung**

**Korrektheit**

* Wenn, wie zuvor umgesetzt, stellen Spin Locks sicher, dass nur ein einziger Thread einen kritischen Abschnitt ausf√ºhren kann 

**Fairness**

* Nope, es kann sein, dass der wartende Thread niemals in den kritischen Abschnitt kommt, und k√∂nnen somit zum ‚Äûverhungern‚Äú eines anderen Threads f√ºhren

**Performanz**

* Jeder wartende Thread nutzt eine Zeitscheibe zum Pr√ºfen, daher auf 1-CPU-Systemen nicht sonderlich performant, auf Multi-CPU Systemen ganz OK, solange Anzahl der Threads ~ Anzahl der CPUs 

### Ansatz 4: Compare-and-Swap

Wird ebenfalls in g√§ngigen Systemen (x86 via `cmpxchg`) eingesetzt[^2]

* Pr√ºft, ob der Wert an Adresse von `ptr` dem Wert von `expected` entspricht 
* Falls ja, wird der Wert von `new` gesetzt 
* Dann wird der (unver√§nderte) Wert von `original`zur√ºck geleifert
* Nutzung analog zu Test-and-Swap

```c
int CompareAndSwap(int *ptr, int expected, int new) {
  int original = *ptr;
  if (original == expected)
    *ptr = new;
  return original;
}
```

### Weitere Ans√§tze

* Weitere (Hardware-basierte) Ans√§tze werden z.B. in OSTEP Kapitel 28 behandelt

  * Load-Linked und Store-Conditional 
  * Fetch-and-Add

* Problem bisher: Thread, der auf den Lock wartet, verschwendet u.U. ganze Zeitscheiben zum warten
Bei $ùëÅ‚àí1$ Threads werden somit $ùëÅ$ Zeitscheiben verschwendet 

* Wie kann also ein Lock entwickelt werden, dass nicht unn√∂tig CPU-Cycles verschwendet?


## Yield

* Anstelle zu warten, kann ein Thread sich selbst mittels `yield` ¬ªentschedulen¬´, d.h. ein anderer Thread wird anstelle dessen geplant 
* Funktioniert gut bei zwei Threads 
* Was aber, wenn viele Threads um das Lock konkurrieren? 
* Dann werden sehr viele Context Switches ausgef√ºhrt, und wie wir wissen, lohnen sich diese erst ab einer gewissen Laufzeit 

```c
void init() { 
  flag = 0;
}

void lock() {
  while (TestAndSet(&flag, 1) == 1)
    yield(); // give up the CPU
}

void unlock() {
  flag = 0;
} 
```

* Bisher wird alles mehr oder weniger dem Zufall √ºberlassen.
* Der Scheduler entscheidet dar√ºber, welcher Thread als n√§chstes ausgef√ºhrt wird 
* Je nachdem welcher Thread ausgew√§hlt wird, wartet dieser auf das Lock oder entschedult (mittels `yield`) sich, w√§hrend ein anderer Thread h√§tte ausgef√ºhrt werden k√∂nnen
* In beiden F√§llen ist dies reine Verschwendung von Rechenkapazit√§t 

Wie kann diese Situation verbessert werden? Hier hilft uns das Betriebssystem! 

# Referenzen

[^1]: https://c9x.me/x86/html/file_module_x86_id_328.html
[^2]: https://c9x.me/x86/html/file_module_x86_id_41.html