<!--

author:   Andreas Heil

email:    andreas.heil@hs-heilbronn.de

version:  0.1

language: de

narrator: DE German Male

tags: betriebssysteme, lecture, scheduler

comment:  

-->


# Virtualisierung

<!-- data-type="none" -->
| Parameter | Kursinformationen |
| --- | --- |
| **Veranstaltung:** | `262007 Betriebssysteme`|
| **Semester** | `SEB2` |
| **Hochschule:** | `Hochschule Heilbronn` |
| **Inhalte:** | `Fortgeschrittene Scheduler` |
| Startseite | [https://liascript.github.io/course/?https://raw.githubusercontent.com/aheil/os/master/README.md#1](https://liascript.github.io/course/?https://raw.githubusercontent.com/aheil/os/master/README.md#1) | 
| **Link auf den GitHub:** | [https://github.com/aheil/os/blob/main/lectures/04_scheduler.md](https://github.com/aheil/os/blob/main/lectures/04_scheduler.md) |
| **Autoren** | @author |


## Lernziele 

* FUnktionsweise realer Scheduler **kennen lernen**

## I/O und Overlapping

* Wir haben zwei Typen von Schedulern kennen gelernt 

  * SJF/STCF optimiert Turnaround-Zeiten, ist jedoch ungÃ¼nstig fÃ¼r Antwortzeiten 
  * RR optimiert die Antwortzeit, ist aber ungÃ¼nstig fÃ¼r die Turnaround-Zeit

* Es gibt auf Basis des vorangehenden Abschnitts noch zwei Annahmen/Restriktionen, die Â»aufgelÃ¶stÂ« werden mÃ¼ssen

  4. Alle Jobs verwenden ausschlieÃŸlich die CPU
  5. Laufzeit eines jedes Jobs ist bekannt

{{1}}
************************************

**Input/Output**

* LÃ¶sen wir daher die nÃ¤chste Restriktion: Ab sofort kÃ¶nnen Jobs auch I/O-Operationen aufrufen
* Scheduler muss nun entscheiden wann eine I/O-Operation durchgefÃ¼hrt wird, da in der Zeit der laufende Prozess die CPU nicht nutzen kann und sich somit im Status Â»blockedÂ« befindet
* Scheduler kann demnach in dieser Zeit einen anderen Job laufen lassen
* Ist die I/O-Operation fertig (wird Ã¼ber Interrupt angezeigt), wird der zuvor geblockte Job wieder auf Â»readyÂ« gesetzt
* Ab jetzt kann er Job potentiell wieder laufen

************************************

{{2}}
************************************

**Overlapping**
s
* Schlechte Ressourcen-Nutzung
![](../img/os.03.schechte_ressourcennutzung.png)

* Bessere Ressourcen-Nutzung dank Overlapping
![](../img/os.03.overlapping.png)

************************************

{{3}}
************************************

**Kein Wissen Ã¼ber Prozessdauer**

* Als letzte Restriktion lÃ¶sen wir nun die Kenntnisse Ã¼ber die Prozesslaufzeit auf 
* D.h. der Scheduler weiÃŸ nichts Ã¼ber die Restlaufzeit eines Prozesses
* Wie kann dann sinnvoll gescheduled werden? 

LÃ¶sungsidee: sog. Â»Multi-Level Feedback QueueÂ«-AnsÃ¤tze verwenden die nahe Vergangenheit, um die Zukunft vorauszusagen! ðŸ¤©

************************************

## Multi-Level Feedback Queue

* Zuletzt wurde die Annahme fallen gelassen, dass wir die Laufzeit eines Prozesses im Vorhinein wissen
* Wie kann ohne diese Kenntnisse ein Scheduler gebaut werden, er sowohl Antwortzeiten (z.B. fÃ¼r interaktive Anwendungen) als auch die Turnaround-Zeiten (d.h. ein Job mÃ¶glichst schnell fertig stellen) ohne Wissen Ã¼ber die Laufzeit eines Prozesses minimiert?

{{1}}
************************************

**LÃ¶sungsidee: Multi Level Feedback Queue (MLFQ)**

Grundlegende Regeln

* MLFQ hat mehrere Queues, jede mit einem PrioritÃ¤ts-Level
* Jobs mit hÃ¶herer PrioritÃ¤t laufen zuerst (=hÃ¶here Queue)
* Falls sich mehrere Jobs in der gleichen Queue befinden gilt:

  * Regel 1: `If Priority(A) > Priority(B), A runs (B doesnâ€˜t)`
  * Regel 2: `If Priority(A) == Priority(B), A & B run in Round Robin`

* Wie wird jedoch die PrioritÃ¤t fÃ¼r ein Job festgelegt?

  * PrioritÃ¤t  nicht fix, sondern hÃ¤ngt vom **beobachteten Verhalten** des Jobs ab

* Wenn die ganze CPU-Zeit auf A und B verteilt wird, wie kommen dann aber C und D zum Zug? 


![](//img/os.03.mlfq.png)

************************************


### 1. Versuch - PrioritÃ¤ten Ã¤ndern

* Workload Betrachtung: Mischung aus...

  * interaktiven Jobs, die kurz laufen, geben CPU schnell wieder frei und
  * langlaufende Jobs, die die CPU-intensiv in Anspruch nehmen, aber deren Antwortzeit Â»nicht relevantÂ« ist. 

* ZusÃ¤tzliche Regeln:

  * Regel 3: Ein neu eintreffender Job erhÃ¤lt immer die hÃ¶chste PrioritÃ¤t (oberste Queue)
  * Regel 4a: Wenn ein Job die gesamte Zeitscheibe aufbraucht, wird seine PrioritÃ¤t herabgestuft (d.h. eine Queue nach unten geschoben)
  * Regel 4b: Wenn ein Job die CPU vor Ablauf der Zeitscheibe freigibt, bleibt er auf der gleichen PrioritÃ¤t (d.h. bleibt in der aktuellen Queue)


{{1}}
************************************

**Beispiel 1: Ein langlaufender Job** 

* Job lÃ¤uft immer bis ans Ende der Time Slice 
* Nach jeder Time Slice wird der Job heruntergestuft
* Am Ende lÃ¤uft der Job auf der niedrigsten PrioritÃ¤t

![](../img/os.04.one_sad_job.png)


************************************

{{2}}
************************************

**Beispiel 2: Ein zusÃ¤tzlicher Â»KurzlÃ¤uferÂ«**

* Bei $ð‘‡ = 100$ trifft ein zweiter, kurzlaufender Job ein
* MLFQ trifft immer die Annahme, dass ein neuer Job ein Â»KurzlÃ¤uferÂ« ist 

![](../img/os.04.kurzlaeufer.png)

************************************

{{3}}
************************************

**Beispiel 3: ZusÃ¤tzliche I/O**

* Mischung aus I/O-intensivem und CPU-intensivem Job
* Nach Regel 4 bleibt der Job, der die CPU schnell freigibt, weil er z.B. auf die Tastatur wartet, hoch priorisiert
* Wer sieht denn das Problem?

![](../img/os.04.io.png)

************************************

{{4}}
************************************

**Game the Scheduler**

* Programm so schreiben, dass es kurz vor Ablauf der Zeitscheibe einen Dateizugriff ausfÃ¼hrt (die Datei selbst ist uns komplett egal)
* Programm bleibt hoch priorisiert, da Zeitscheibe nicht vollstÃ¤ndig aufgebraucht
* Machen wir das immer bei â‰ˆ 99% der Zeitscheibe, kÃ¶nnten wir die CPU 99% Ã¼bernehmen
* Langlaufende Jobs bleiben auf der Strecke (engl. starvation)
* Job A kommt nie mehr in eine bessere Queue, selbst wenn sich sein Verhalten Ã¤ndert 


Wie kÃ¶nnten wir das besser machen?

![](../img/os.04.game_the_scheduler.png)

************************************

### Versuch 2: Priority Boost

* Neue Regel
    
    * Regel 5: Nach definierten Zeit *s* werden alle Jobs wieder in die oberste Queue verschoben

* Regel 5 lÃ¶st zwei Probleme:

    * Prozesse laufen nicht mehr Gefahr der Â»StarvationÂ«
    * Wenn ein Job Â»plÃ¶tzlichÂ« interaktiv wÃ¼rde, kann er entsprechend priorisiert werden (s. nÃ¤chste Seite)

{{1}}
************************************

**Voodoo Constant** 

Spannende Frage: Wie lange sollte die Zeitspanne *s* sein?

* Der Wert *s* heiÃŸt nach John Ousterhout Â»Voodoo ConstantÂ«.
* FÃ¼r die Bestimmung sog. Voodoo-Konstanten benÃ¶tigt das System etwas Â»schwarze MagieÂ« zu deren Bestimmung
* Dilemma: Wenn *s* zu groÃŸ gewÃ¤hlt wird, kÃ¶nnen CPU-intensive Jobs doch verhungern, ist sie zu klein gewÃ¤hlt bekommen interaktive Jobs nicht genÃ¼gend CPU  
* Generell sollten Voodoo-Konstanten vermieden werden (Ousterhout's Law)

************************************


### Versuch 3: Verbesserte BuchfÃ¼hrung

* Problem: Regel 4a und 4b ermÃ¶glichen immer noch, dass der Scheduler ausgespielt wird 
* LÃ¶sungsidee: Eine verbesserte BuchfÃ¼hrung
* Merken wie viel Zeit ein Prozess in einer Queue verbracht hat
* Sobald ein Prozess kumuliert eine Zeitscheibe aufgebraucht hat, wandert er eine Queue nach unten
* Aus den Regeln 4a und 4b wird
  * Regel 4: Sobald ein Job seine gesamte Zeit auf einer PrioritÃ¤tsebene genutzte hat (ungeachtet dessen, wie viel Zeit er der CPU  Â»zurÃ¼ck gibtÂ«), wird seine PrioritÃ¤t reduziert (d.h. er wandert eine Queue nach unten).

{{1}}
************************************

**Tuning und MLFQ Probleme** 

* Wie sollte MLFQ priorisiert werden?
* Wie viele Queues 
* Wie groÃŸ sollte die Zeitspanne (engl. time slice) pro Queue sein?
* Machen unterschiedliche Time Slices pro Queue Sinn?
* Wie oft findet Priority Boost statt?

************************************

{{2}}
************************************

**MLFQ Regeln** 

* **R 1**: If Priority(A) > Priority(B), A runs (B doesnâ€™t)
* **R 2**: If Priority(A) = Priority(B), A & B run in round-robin fashion using the time slice (quantum length) of the given queue.
* **R 3**: When a job enters the system, it is placed at the highest priority (the topmost queue).
* **R 4**: Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).
* **R 5**: After some time period *s*, move all the jobs in the system to the topmost queue. 

************************************

{{3}}
************************************

**Wird MLFQ Ã¼berhaupt irgendwo verwendet?**

* Solaris

  * MLFQ *Time-Sharing Scheduling Class* wird Ã¼ber eine Reihe von Tabellen konfiguriert
  * Diese kÃ¶nnen durch einen Admin angepasst werden ðŸ˜±
  * 60 Queues, mit langsam steigenden Time Slices von 20 ms bis zu 1 Sekunde 

* FreeBSD 

  * Scheduler nutzt Formel um PrioritÃ¤t eines Jobs zu berechnen
  * Wie viel CPU hat der Prozess schon verbraucht + wie ist  der Verbrauch abgefallen (sog. Decay-Usage Algorithms)

************************************

{{4}}
************************************

**Be Nice** 

* Unix Betriebssysteme nehmen Â»HinweiseÂ« von Nutzern und Administratoren bzgl. der Priorisierung von Jobs entgegen. 
* Unter Windows kann man beim Start eines Prozesses mittels `start` die PrioritÃ¤t des Prozesses angeben
* Hausaufgabe: Machen Sie sich mit dem Befehl `nice` (Linux) und `start` (Windows) vertraut

![](img/os.04.benice.png)

************************************

### 