<!--

author:   Andreas Heil

email:    andreas.heil@hs-heilbronn.de

version:  0.1

language: de

narrator: DE German Male

tags: betriebssysteme, lecture, dateisysteme

comment:  

-->


# Dateisysteme

<!-- data-type="none" -->
| Parameter | Kursinformationen |
| --- | --- |
| **Veranstaltung:** | `262007 Betriebssysteme`|
| **Semester** | `SEB2` |
| **Hochschule:** | `Hochschule Heilbronn` |
| **Inhalte:** | `Dateisysteme` |
| Startseite | [https://liascript.github.io/course/?https://raw.githubusercontent.com/aheil/os/master/README.md#1](https://liascript.github.io/course/?https://raw.githubusercontent.com/aheil/os/master/README.md#1) | 
| **Link auf den GitHub:** | [https://github.com/aheil/os/blob/gh-pages/lectures/11_dateisysteme.md](https://github.com/aheil/os/blob/gh-pages/lectures/11_dateisysteme.md) |
| **Autoren** | @author |

## Lernziele und Kompetenzen

Den Aufbau von Hard Disk Drives und RAID-Systemen **kennen lernen** und die Prinzipien bei der Ansteuerung durch das Betriebssystem **verstehen**. 

## Datenpersistenz

* Hard Disk Drives (dt. Festplatten sind die seit Jahrzehnten am weit verbreitetsten Art Daten zu speichern
* Dateisysteme h√§ngen dabei stark von den darunterliegenden Ger√§ten ab

  * Wie speichern moderne Hard Disks √ºberhaupt Daten ab?
  * Wie sieht das Interface hierf√ºr aus?
  * Wie sind die Daten konkret angeordnet und wie wird darauf zugegriffen?
  * Wie l√§sst sich mit ‚ÄûDisk Scheduling‚Äú die Leistung verbessern?
  * Welche Konsequenz hat der Wandel von klassischen Festplatten hin zu Solid State Disks (Abk. SSD)?

{{1}}
************************************

**Das Interface**

Der Aufbau ist im Grundprinzip immer √§hnlich

* Das Laufwerk besteht aus einer Anzahl von sog. Sektoren
  (i.d.R. in Form von 512-Byte Bl√∂cken)
* Jeder Block kann individuell gelesen und geschrieben werden
* Alle Sektoren sind nummeriert 0 bis $n‚àí1$ (bei $n$ Sektoren) 
* Multi-Sektor-Operationen sing m√∂glich (und g√§ngig)
* Viele Dateisysteme lesen 4KB oder mehr auf einmal 
* Atomare Schreiboperationen sind nur auf 512-Byte Bl√∂cke zugesichert 

************************************

{{2}}
************************************
**Torn Write**

Was bedeutet atomare Schreiboperationen sind nur auf 512-Byte Bl√∂cken zugesichert?

![](../img/os.11.torn_write.de.png)

Nur die ersten drei Bl√∂cke wurden geschrieben, obwohl der Stromausfall erst sehr sp√§t  bei der Schreiboperation von Block 4 aufgetreten ist

************************************

{{3}}
************************************

**Inoffizielle Annahmen**

* Annahmen, die von vielen Clients getroffen werden (unwritten contract):

  * Auf zwei nahe beieinander liegende Bl√∂cke kann schneller zugegriffen werden, als auf weit entfernt liegende
  * Der Zugriff auf fortlaufende B√∂cke (engl. sequential read/write) ist der schnellste Zugriff √ºberhaupt und gew√∂hnlich  schneller als der wahlfreie Zugriff (engl. random access)

  > Angenommen, Sie schreiben einen Treiber f√ºr (konventionelle) Festplatten unter diesen  Annahmen und morgen tauscht jemand die Festplatten gegen Solid State Disks aus, was passiert dann?

************************************

## Geometrie 

**Grundlegende Geometrie**

  * Eine oder mehrere Scheiben (engl. platter), jede mit je zwei Seiten
  * Magnetische Oberfl√§che aus Eisenoxid - oder Kobalt-Deckschicht (engl. surface)
  * Achse bzw. Spindle (engl. spindle)
  * Schreib-/Lesekopf (engl. disk-head)
  * Arm mittels dem der Schreib-/Lesekopf positioniert wird (engl. disk arm)
  * Daten sind in konzentrischen Kreisen (engl.tracks) angeordnet
  * Umdrehung wird in RPM (rotations per minute) gemessen.
  * Typische Werte heutzutage von 7.200 bis 15.000 RPM
  * Interessant wird die Umdrehungszeit, bei 10.000 RPM sind dies ca. 6ms

{{1}}
************************************
  
**Eine einfache Festplatte**

* Einige (vereinfachende) Annahmen

  * Ein Track
  * Track besteht aus 12 Sektoren bzw. Bl√∂cken (Sektoren)
  * Jeder Block besteht aus 512 Byte
  * Die Scheibe dreht sich gegen der Uhrzeiger Sinn

![](../img/os.11.simple_disk.de.png)

************************************

{{2}}
************************************

**Rotational Delay**

* Rotational Delay oder auch Rotational Latency ‚Äì Zeit bis sich der gesuchte Sektor unter dem Schreib-Lese-Kopf befindet 
* Eine vollst√§ndige Umdrehung dauert $R$ 
* Suchen wir Sektor 0 und starten bei Sektor 6, ist das Delay $R/2$
* Der Worst-Case w√§re im Beispiel zuvor ein Start bei 5, hier wird fast eine ganze Rotation ben√∂tigt und das Delay betr√§gt somit fast $R$

************************************

{{3}}
************************************

**Seek Time**

* In Wirklichkeit besitzen HDDs **sehr viele** Tracks und der Schreib-/Lesekopf muss permanent ausgerichtet werden

  * Hier: Kopf √ºber dem innersten Track muss zum √§u√üersten bewegt werden (engl. seek):
  * Rotation und Seek sind mit die teuersten Operationen einer Festplatte
  * Seeking besteht aus vier Phasen:

    * Beschleunigung (engl. acceleration)
    * Schub bei voller Geschwindigkeit (engl. coasting)
    * Abbremsung (engl. deceleration)
    * Einschwingzeit (engl. settling time) mit 0,5 bis 2ms

![](../img/os.11.seek_time.de.png)

************************************

{{4}}
************************************

**Transfer und andere unwichtige Dinge**

Erst wenn der Kopf korrekt positioniert ist (stellen Sie sich vor, er w√§re nur ungef√§hr auf dem richtigen Trackü§¶‚Äç‚ôÇÔ∏è) findet der Transfer (engl.transfer) statt.

Um dass sequentielle Lesen zu erm√∂glichen, nutzen manche Disks ein sog. Spurversatz (engl. trackskew) an, damit keine Latenz nach dem Neupositionieren entsteht, wenn die Daten auf einem anderen Sektor weitergef√ºhrt werden.

Au√üen befinden sich mehr Sektoren (Physik rulez!), daher werden Platten oft in Zonen (engl. multi-zoned disks). √Ñu√üere Zonen besitzen dann mehr Sektoren als innere.

Schreib-/Lesecache zur Performance-Steigerung. Beim Schreiben kann sofort nach dem Cachen best√§tigt werden (engl.writeback) oder erst nach dem Schreiben auf Platte (engl.writethrough).

************************************

{{5}}
************************************

**I/O Zeiten**

Wie setzt sich nun die Zeit f√ºr einen I/O-Zugriff zusammen?

$$T_{I/O}=T_{seek} +T_{rotation}+T_{transfer}$$

F√ºr den Plattenvergleich gerne genutzt: I/O Rate:

$$ R_{I/O} = {\frac{Size_{transfer}}{T_{I/O}}} $$

![](../img/os.11.disc_spec.de.png)

************************************

## Disk Scheduling

* Aufgrund der hohen Kosten f√ºr Disk Zugriffe entscheidet der Disk Scheduler √ºber die Zugriffe:

  * Anders als bei Prozessen kann man bei Plattenzugriffen die Dauer gut berechnen
  * Auf Basis von Seek-Zeiten und der Rotation Delay kann der k√ºrzeste Job gefunden werden

{{1}}
************************************

 **Shortest Seek Time First (SSTF)**

  * Anordnung der Jobs nach Track ‚Äì die Anfrage mit dem am n√§chst gelegenen Track wird zuerst gew√§hlt
  * Problem: Die Disk Geometrie ist dem Betriebssystem nicht bekannt
  * Anstelle dessen kann der n√§chst gelegen Block verwendet werden (nearest-block-first, Abk. NBF)
  * Problem 2: Starvation‚Äì Bei einem fortlaufenden Strom von Anfragen auf z.B. die inneren Tracks w√ºrden Anfragen auf die √§u√üeren ignoriert
  * Wie kann dieses Problem gel√∂st werden?

************************************

{{2}}
************************************

**SCAN**

* Anfragen werden von den √§u√üeren zu den inneren Tracks und wieder zur√ºck etc. abgearbeitet (engl. sweep)

**C-SCAN (Circular SCAN)**

  * Anstelle in beiden Richtungen werden Anfragen immer von den √§u√üeren Tracks abgearbeitet
  * Fairer gegen√ºber den √§u√üeren und inneren Tracks, da reines SCAN zweimal die mittleren Tracks trifft
  * Allerdings werden SCAN/C-SCAN nicht ann√§hernd einem SJF-Ansatz gerecht

************************************

{{3}}
************************************

**Shortest Positioning Time First (SPTF)**

manchmal auch : Shortest Access Time First (SATF)

* Ausgangspunkt s. vorherige Abbildung
* Sollte nun Track 8 oder 16 zuerst gew√§hlt werden?
* Abh√§ngig von Seek-Zeit und Rotation-Delay
* L√∂st eigentlich unsere vorherigen Probleme
* Problem: Das Betriebssystem kennt meist nicht die Track-Grenzen nicht und wei√ü nicht wo sich der Schreib-Lese-Kopf gerade befindet
* Daher wird SPFT meist innerhalb des Drives selbst implementiert

************************************

{{4}}
************************************

**Weiter Herausforderungen**

* Fr√ºher wurde das gesamte Scheduling im Betriebssystem realisiert ‚Äì fr√ºher waren die Disks ‚Äûeinfacher‚Äú gebaut.
* Heute besitzen Festplatten einen komplexen Scheduler auf dem Disk Controller, der exakte Daten √ºber die internen Positionen hat.
* Das Betriebssystem schickt die Requests an die Disk, die es am geeignetsten h√§lt und die Disk k√ºmmert sich um den Rest.
* I/O Merging: Requests, die nahe aneinander liegende Sektoren betreffen, sollten m√∂glichst zusammengefasst werden, da dies den Overhead f√ºr das Betriebssystem reduziert.
* Wie lange soll der Scheduler warten, bis eine I/O-Anfrage abgearbeitet wird? Es k√∂nnte ja noch eine ‚Äûbessere‚Äú Anfrage kommen, so dass die Disk effizienter genutzt werden kann.

************************************

## RAID Systeme

**Einf√ºhrung**

Festplatten geh√∂ren zu den **langsamsten** Komponenten in einem Rechner. Wenn eine Festplatte ausf√§llt, sind die persistierten Daten verloren. Au√üer Sie haben ein Backup, aber das ist hier nicht der Punkt, wicht hier ist jedoch: RAID ist kein Backup!

Zun√§chst die Frage: Wie kann ein gro√ües, schnelles und zuverl√§ssiges Speichersystem geschaffen werden?

* Von au√üen betrachtet sieht ein RAID wie _eine_ Festplatte aus. 
* Intern ist ein RAID jedoch ein h√∂chst komplexes System mit zahlreichen Vorteilen: 
  * Performance, Speicherplatz (Kapazit√§t) und Zuverl√§ssigkeit
  * RAID Systeme verkraften au√üerdem den Ausfall einzelner Festplatten

{{1}}
************************************

**Interface**

F√ºr das Dateisystem sieht ein RAI- System aus wie eine einzelne Festplatte (warum es das nicht ist kl√§ren wir sp√§ter).

* Bei einem Request durch das Betriebssystem, muss das RAID ermitteln auf welche Disk (bzw. abh√§ngig vom RAID Level, auf welche Disks) zugegriffen werden muss.

* Da die Daten auf mehrere Disks verteilt sind, m√ºssen mehrere physikalische I/O-Zugriffe pro logischen I/O-Zugriff stattfinden.

************************************

## RAID Charakteristika

Auf Basis welcher Kriterien k√∂nnen RAID-Systeme evaluiert werden?


{{1}}
************************************

**Kapazit√§t**

* Wie viel effektiver Speicherplatz ist verf√ºgbar, wenn $N$ Disks mit $B$ Bl√∂cken verwendet werden? 
Ohne Redundanz sind dies $ùëÅ\cdotùêµ$
* Wenn zwei Kopien vorgehalten werden (engl. mirroring) w√§ren dies $(ùëÅ\cdotùêµ)‚àï2$
* Verschiedene RAID-Level liegen irgendwo dazwischen 

************************************

{{2}}
************************************

**Zuverl√§ssigkeit**

* Zur Vereinfachung gehen wir derzeit von einem einzigen Fehlermodell aus: Eine Disk f√§llt komplett aus, einem sog. Fail-Stop.
* Des weiteren gehen wir davon aus, dass der RAID-Controller dies auch direkt feststellen kann.
  * Wie viele Disks k√∂nnen ausfallen, so dass das jeweilige RAID-Design immer noch funktionsf√§hig ist?

Es gibt nat√ºrlich noch mehr Fehlerf√§lle, die wir sp√§ter betrachten!

************************************

{{3}}
************************************

**Performance**

* Die Performance ist nicht ganz einfach zu bestimmen:

  * H√§ngt vom jeweiligen Workload ab
  * Wie hoch ist die Schreibe- oder Lesegeschwindigkeit?
  * Wie wir vorher gelernt haben, h√§ngt dies auch von den eingesetzten Disks ab

************************************

## RAID Level

### RAID Level 0

**Basics**

  * Keine Redundanz
  * Mehrere Disks werden genutzt, um die Kapazit√§t zu erh√∂hen (engl.striping)
  * Einfachste Form: Bl√∂cke werden √ºber die Disks verteilt
  * Werden Bl√∂cke nun sequentiell gelesen, kann dies parallelisiert werden!

{{1}}
************************************

**Stripes**

![](../img/os.11.stripes.de.png)

Bl√∂cke in der gleichen Reihe werden *Stripes* genannt.

************************************

{{2}}
************************************

**Chunk Size**

  * Besser: Mehrere Bl√∂cke auf einer Disk
  * Hier: Zwei 4-KB Bl√∂cke bevor zur n√§chsten Disk gesprungen wird

![](../img/os.11.many_stripes.de.png)

  * Performance Auswirkung:

    * Kleine Chunk Sizes: Dateien werden √ºber viele Disks verteilt
    * Gro√üe Chunk Sizes: Intra-File Parallelit√§t wird reduziert
    * Richtige Gr√∂√üe: schwer zu bestimmen bzw. ‚Äûit depends‚Äú

************************************

{{3}}
************************************

**RAID-0 Analyse**

**Kapazit√§t**
 * Bei $ùëÅ$ Disk mit je $ùêµ$ Bl√∂cken liefert RAID-0 ein perfektes Ergebnis: $ùëÅ\cdotùêµ$

**Zuverl√§ssigkeit**

* Perfekt, was die Ausfallwahrscheinlichkeit angeht: Bei einem Fehler sind die Daten futsch! 

**Performance**
* Bei einem Zugriff auf einen einzelnen Block: Vergleichbar mit einzelner Disk
* Bei sequentiellen Zugriffen: Volle Parallelit√§t
* Bei wahlfreien Zugriffen1 $ùëÅ\cdot ùëÖ$ MB/s mit 
  $ùëÖ=(ùê¥ùëöùëúùë¢ùëõùë° ùëúùëì ùê∑ùëéùë°ùëé)/(ùëáùëñùëöùëí ùë°ùëú ùê¥ùëêùëêùëíùë†ùë†)$

F√ºr eine detaillierte Berechnung sei hier auf OSTEP Kapitel 38\.4 verwiesen

************************************

### RAID Level 1

**Mirroring**

* Jeder Block wird im System auf eine andere Disk kopiert (bzw. gespiegelt)

  ![](../img/os.11.raid-1.de.png)

* Hier: RAID-10 bzw. RAID 1+0, nutzt gespiegelte Paare von Disk
* Alternativ: RAID-01 bzw. RAID 0+1, besteht aus zwei RAID-0 Arrays, die gespiegelt sind

{{1}}
************************************

**RAID-1 Analyse**

**Kapazit√§t**

* Es wird nur die H√§lfte der Kapazit√§t genutzt: $(ùëÅ\cdotùêµ)‚àï2$ und somit teuer

**Zuverl√§ssigkeit**

* Ausfall einer Diks wird verkraftet, im vorherigen Fall k√∂nnen sogar Konstellationen von Disks ausfallen (z.B. Disk 0 und 2), darauf sollte man aber nicht wetten

**Performance**

* Einzelne Leseoperation vergleichbar mit einer einzelnen Disk
* F√ºr einen Schreibzugriff m√ºssen jedoch zwei (parallele) physikalische Schreiboperationen durchgef√ºhrt werden, im Worst-Case muss auf den langsamsten Schreibprozess gewartet werden (z.B. aufgrund von Rotation Delay)
*  Sequentielle Schreib- und Leseoperationen dauern $(ùëÅ/2\cdotùëÜ)$ MB/s mit $ùëÜ=(ùê¥ùëöùëúùë¢ùëõùë° ùëúùëì ùê∑ùëéùë°ùëé)/(ùëáùëñùëöùëí ùë°ùëú ùê¥ùëêùëêùëíùë†ùë†)$ bzw. die H√§lfte des H√∂chstdurchsatzes
* Wahlfreie Leseoperationen sind mit $ùëÅ\cdotùëÖ$ MB/s die beste Operation f√ºr RAID-1, wogegen wahlfreie Schreiboperationen mit $ùëÅ/2\cdotùëÖ$ MB/s weniger geeignet sind, da zwei physikalische Schreiboperationen simultan durchgef√ºhrt werden m√ºssen. 

F√ºr eine detaillierte Berechnung sei auch hier auf OSTEP Kapitel 38.4 verwiesen

************************************ 

### RAID Level 4

* Nutzung eines sog Parit√§tsbits
* Ben√∂tigt weniger Speicherplatz als gespiegelte RAIDs, jedoch auf Kosten der Performance

![](../img/os.11.parity_bit.de.png)

* Mittels der XOR-Funktion wird das Parit√§tsbit berechnet

{{1}}
************************************

**Parity-Bit**

  * Invariante
  * Pro Zeile gerade Anzahl von 1en\, einschl. des Parit√§tsbits
  * RAID muss dies sicherstellen
  * Beim Ausfall einer Zeile C \(s\.o\.\) kann diese wiederhergestellt werden
    * Wie? XOR auf die verbleibenden Spalten ausf√ºhren
  * Aber bei Bl√∂cken?
  * Bitweises XOR auf den ganzen Block \(z\.B\. 4 KB\)

 ![](../img/os.11.xor.de.png)

************************************

{{2}}
************************************

**RAID-4 Analyse **

**Kapazit√§t**
* 1 Disk f√ºr Parit√§ten ergibt eine Gesamtkapazit√§t $(ùëÅ‚àí1)\cdotùêµ$

**Zuverl√§ssigkeit**
* RAID-1 erlaubt den Ausfall einer Disk

**Performance**
* Sequentielle Leseoperationen k√∂nnen alle Disks (ohne die Parit√§tsdisk) nutzen und liefern so einen Maximaldurchsatz von $(ùëÅ‚àí1)\cdotùëÜ$ MB/s
* Bei einem sog. Full Stripe Write wird ein gesamter Stripe auf einmal beschrieben und der Parit√§tsblock kann direkt mit berechnet werden, alle Schreiboperationen k√∂nnen parallel stattfinden (effizienteste Schreiboperation im RAID-4)
* Die effektive Bandbreite bei sequentiellen Schreiboperationen ist dabei 
  $(ùëÅ‚àí1)\cdotùëÜ$ MB/s
* Wahlfreie Leseoperationen liegen bei $(ùëÅ‚àí1)\cdotùëÖ$ MB/s
* Beim Schreiben eines einzelnen Blocks muss das Parit√§tsbit des Stripes neu berechnet werden

**Variante 1: Additive Parity**
* Alle bestehenden Bl√∂cke (parallel) lesen und mit dem neune Block `XOR`
* Neu berechneter Parit√§tsblock und neuer Block k√∂nnen parallel geschrieben werden

**Variante 2: Subtractive Parity**
* Alter Wert wird gelesen, ist dieser mit dem neuen Wert identisch muss das Parit√§tsbit nicht ge√§ndert werden, falls doch, muss das Parit√§tsbit umgedreht werden
* Bei ganzen Bl√∂cken (z.B. 4 KB) wie in RAID-4 sind dies 4096 mal 8 Bit. 
* Der Einsatz des jeweiligen Verfahrens h√§ngt also wieder davon ab (‚Äûit depends‚Äú) 

> Auf jeden Fall wird die Parit√§tsdisk zum Flaschenhals

************************************

### RAID Level 5

* Grundlegend gleich zu RAID-4, jedoch mit den Parit√§tsbl√∂cken √ºber die versch\. Disks verteilt (engl. rotating parity)

![](../img/os.11.rotating_parity.de.png)

> Flaschenhals wird somit beseitigt

{{1}}
************************************

**RAID-5 Analyse**

  * Die meisten Werte sind identisch zu RAID-4
  * Wahlfreie Leseoperationen sind etwas besser, da alle Disks genutzt werden k√∂nnen
  * Wahlfreie Schreiboperationen verbessern sich signifikant, da Requests nun parallel ausgef√ºhrt werden k√∂nnen.

************************************
