<!--

author:   Andreas Heil
email:    andreas.heil@hs-heilbronn.de
version:  0.2
language: de
narrator: DE German Male

comment:  

-->

[![LiaScript](https://raw.githubusercontent.com/LiaScript/LiaScript/master/badges/course.svg)](https://LiaScript.github.io/course/?https://github.com/aheil/os) 


# Betriebssysteme

Dieser Kurs ist Teil des Bachelor Studiengangs Software Engineering (SEB) und an der Hochschule Heilbronn.

Dies ist das Repository der Kursinformationen. Diese Seiten sind als [interaktiver Kurs verfÃ¼gbar](https://liascript.github.io/course/?https://github.com/aheil/os) verfÃ¼gbar.

Die Vorlesung Betriebssysteme (262007) wird von mir sowohl im Sommer- als auch dem Wintersemester im Kurs SEB2 angeboten. Die Vorlesungssprache ist Deutsch.

Die Veranstaltung basiert dabei auf dem Buch [Operating Systems: Three Easy Pieces](http://pages.cs.wisc.edu/~remzi/OSTEP/) von Rezi H. und Andrea C. Arpaci-Dussseau.

Die Vorlesung wird dabei von mir um praktische ProgrammÃ¼bungen ergÃ¤nzt.

Veranstaltungsbegleitend empfehle ich die Ãœbungsaufgaben aus dem Buch zu bearbeiten.

Das Buch ist als [freies PDF Buch]((http://pages.cs.wisc.edu/~remzi/OSTEP/)) erhÃ¤ltlich. ZusÃ¤tzlich finden Sie Print-Exemplare in der Bibliothek bzw. in meinem Semesterapparat am Campus Sontheim.

FÃ¼r Student:innen in meinem Kurs gibt es in jedem Semester ein [ILIAS Raum](https://ilias.hs-heilbronn.de/goto.php?target=crs_360705&client_id=iliashhn) mit Forum.

## KursÃ¼bersicht

**Dozent**

Prof. Andreas Heil

**Kursnummer**

262007 (SEB/SPO4)

**Level**

Grundstudium Bachelor

**Semesterwochenstunden/ECTS**

2/3

**Workload**

- 30h Kontaktstunden/Lerneinheiten
- 90h Selbststudium

**Kurszeiten** 

* 1 Vorlesungseinheit / Woche, 90 Min. / Einheit

Die genauen Veranstaltungszeiten entnehmen Sie bitte dem aktuellen [Stundenplan](https://splan.hs-heilbronn.de/). 

**Voraussetzungen**

Grundlegende Programmierkenntnisse als auch ein grundlegendes VerstÃ¤ndnis fÃ¼r das Themengebiet der Informatik sind hilfreich.  

Sie sollten daher die Veranstaltung *261703 Interaktive Programme* als auch *261701 Grundlagen der Informatik* besucht und erfolgreich bestanden haben. 


**Beschreibung**

Die Studierenden kennen Aufgaben, Architektur, Komponenten und Funktionsweise sowie Klassifikationen von klassischen und modernen Betriebssystemen und haben grundlegende praktische Erfahrung mit unterschiedlichen aktuellen Betriebssystemen.

- Sie wissen, wie Prozesse oder Threads beschrieben und
kontrolliert werden kÃ¶nnen.
- Sie sind in der Lage mit NebenlÃ¤ufigkeit in eigenen
Anwendungen umzugehen und die bekannten SynchronisationsmÃ¶glichkeiten sowie Verfahren zur Vermeidung, Umgehung oder AuflÃ¶sung von Deadlocks korrekt einzusetzen.
- Die Studierenden kennen die wichtigsten Verfahren und Strategien des Speichermanagements sowie unterschiedliche
Scheduling-Methoden, und sie sind in der Lage, diese in eigenen Anwendungen vorteilhaft einzusetzen.
â€¢ Sie kÃ¶nnen die Eignung verschiedener Betriebssysteme oder Betriebssystemkonzepte fÃ¼r neue Anwendungen, Systemanforderungen oder Rechnerarchitekturen einschÃ¤tzen.

**Vorlesung**

Jede Vorlesung behandelt ein spezielles Thema. 

Die Veranstaltung basiert dabei auf dem Buch Operating Systems: Three Easy Pieces von Rezi H. und Andrea C. Arpaci-Dussseau.

Veranstaltungsbegleitend empfehle ich die Ãœbungsaufgaben aus dem Buch zu bearbeiten.

**Klausur**

Nach der Vorlesung findet im PrÃ¼fungszeitraum eine abschlieÃŸende Klausur statt. Die Klausur muss mit mindestens einer 4.0 bestanden werden, um den Kurs insgesamt zu bestehen.  

Die Dauer der Klausur betrÃ¤gt 90 Minuten. 

Das Klausurergebnis geht dabei mit insgesamt 70% in die Bewertung der Gesamtnote ein.

**Hausaufgaben**

Es gibt nicht bewertete Ãœbungen bzw. Hausaufgaben zu jedem Buchkapitel. Ich empfehle die Aufgaben in kleineren Lerngruppen zu bearbeiten und die Themen so aus der Vorlesung zu vertiefen.

ZusÃ¤tzlich gibt es zu manchen Vorlesungseinheiten Tutorials oder Ãœbungen, die optimalerweise im Selbststudium erarbeitet werden.

Insgesamt gibt es drei C ProgrammierÃ¼bungen, die von Ihnen in einer kleinen Gruppe bearbeitet werden. 

Die GruppengrÃ¶ÃŸen sind abhÃ¤ngig von der jeweiligen KursgrÃ¶ÃŸe (2er- bis 4er-Gruppen). Die Gruppen bleiben bis zum Ende des Vorlesungszeitraums fÃ¼r alle Abgaben bestehen. Die Kurse werden nach der ersten Vorlesungseinheit zufÃ¤llig festgelegt und bekanntgegeben.
Die Programmieraufgaben werden durch die Team-Mitglieder in GitLab eingecheckt und mit dem hochschuleigenen Commit-System eingereicht. 
Die Programmieraufgaben werden zu einer gegebenen Deadline eingereicht. Nachfristen werden nicht gewÃ¤hrt. Einreichungen auf anderem Weg als der oben beschriebene, werden nicht gewertet.

Die Ergebnisse der ProgrammierÃ¼bungen gehen mit insgesamt 30% in die Gesamtnote ein.

**Abgaben**

SÃ¤mtliche Abgaben erfolgen Ã¼ber das fakultÃ¤tsinterne Commit-System unter [https://commit.it.hs-heilbronn.de](https://commit.it.hs-heilbronn.de).
Das Commit-System ist nur aus dem Hochschulnetz bzw. Ã¼ber VPN erreichbar.

* Link zum Commit-System: [https://commit.it.hs-heilbronn.de](https://commit.it.hs-heilbronn.de) (nur im Hochschulnetz oder via VPN)
* Link zu GitLab: [https://gitlab.it.hs-heilbronn.de](https://gitlab.it.hs-heilbronn.de)

Zur Abgabe ist es erforderlich, dass die Aufgaben zuvor im hochschuleigenen GitLab unter [https://gitlab.it.hs-heilbronn.de](https://gitlab.it.hs-heilbronn.de) eingecheckt werden. ZugÃ¤nge zu dem System werden in den ersten drei Wochen des Semesters ausgegeben.


**Benotung**

Die Note ergibt sich aus insgesamt 100 Punkten: 

| AktivitÃ¤ten | Anteil an der Note |
| --- | --- | 
| Programmieraufgaben | 30% |
| Klausur | 70 % | 

FÃ¼r das Bestehen des Kurses ist das Bestehen der Klausur mit mind. einer 4,0 erforderlich.

Durch Nichteinreichen der Programmieraufgaben (oder Ergebnisse schlechter 4,0) kann sich Ihre Gesamtnote verschlechtern.

Beispiel: Sie haben in der Klausur eine 4.0 erhalten und keine Programmieraufgaben eingereicht. So ergibt dies insgesamt eine Note schlechter als 4,0 wodurch der Kurs als nicht bestanden gewertet wird. 

Sollten Sie die Klausur nicht bestehen, werden Ihnen die Ãœbungsaufgaben fÃ¼r das kommende Semester **nicht** angerechnet. Die Abgaben sind erneut einzureichen.

**Zusammenarbeit**

 Programmieraufgaben sind in der zugeteilten Gruppe zu bearbeiten. Bei Gruppenabgaben werden alle Team-Mitglieder gleichermaÃŸen bewertet, auÃŸer mind. ein Team-Mitglied beschwert sich hinsichtlich der Bewertung. In diesem Fall findet anstelle dessen eine individuelle Bewertung statt.

Es wird empfohlen auch die Ãœbungsaufgaben aus dem Buch in Gruppen zu erarbeiten und zu diskutieren. 
Lediglich bei den Tutorials empfiehlt es sich diese zunÃ¤chst im Selbststudium zu erschlieÃŸen, bevor diese in der Gruppe be- oder nachbearbeitet werden.

**Lizenz**

Sofern nicht anders angegeben, steht das gesamte Kursmaterial unter einer [Creative Commons Namensnennung 4.0 International Lizenz](https://creativecommons.org/licenses/by/4.0/). 

## Kalender 

| Einheit # | Datum | Thema |
| --- | --- | --- |
|  1 | 29.09.2022 | EinfÃ¼hrung in Git |
|  2 | 06.10.2022 | Virtualisierung | 
|  3 | 13.10.2022 | Scheduling |
|  4 | 20.10.2022 | N.N. | 
|  5 | 27.10.2022 | N.N. | 
|  6 | 03.11.2022 | N.N. | 
|  7 | 10.11.2022 | N.N. | 
|  8 | 17.11.2022 | N.N. | 
|  - | 24.11.2022 | EntfÃ¤llt (Fortbildung) | 
|  - | 01.12.2022 | EntfÃ¤llt (Blockwoche SEB) |
| 09 | 08.12.2022 | N.N. | 
| 10 | 15.12.2022 | N.N. | 
| 11 | 22.12.2022 | N.N. | 
| - | 29.12.2022 | Vorlesungsfrei |
| - | 05.01.2023 | Vorlesungsfrei | 
| 12 | 12.01.2023 | N.N. |
| 13 | 19.01.2023 | N.N. | 

## EinfÃ¼hrung in Git 

### Lernziele

- HintergrÃ¼nde von Versionsverwaltung kennenlernen
- Git Grundlagen kennenlernen
- Verstehen warum Git Workflows hilfreich sind

### Was ist Versionsverwaltung?

Es gibt alternative Bezeichnungen:

- Version Control Systems (VCS)
- Source Control Management (SCM)
- Revision Control Systems (RCS)

Software Projekte kÃ¶nnen schnell sehr groÃŸ und unÃ¼bersichtlich werden.

- Hunderte bzw. tausende von Code-Dateien 

Sehr viele Entwickler kÃ¶nnen an einem Projekt beteiligt sein. 

- Versionsverwaltungen kÃ¶nnen helfen diese KomplexitÃ¤t in den Griff zu bekommen, indem die Ã„nderungen an den Dateien Ã¼ber die Zeit hinweg protokolliert werden.

Historie: Selbst fÃ¼r einzelner Entwickler sinnvoll

- Ã„nderungen Ã¼ber die Zeit sehen kÃ¶nnen
- "ZurÃ¼ckrollen" zu einem bestimmten Zeitpunkt 
- Was wÃ¤re die Alternative? Viele (sehr viele) Kopien einer Datei?

Mehrere Entwickler

- Sehen, wer welche Ã„nderungen gemacht hat 
- Konflikte auflÃ¶sen, wenn mehrere Entwickler Ã„nderungen an der gleichen Datei/der gleichen Zeile durchgefÃ¼hrt haben 

Versionierung 

- Zustand eines Projekts wiederherstellen: zum Testen, fÃ¼r ein Release oder um die EinfÃ¼hrung eines Fehlers zu finden 


### Was nutzen Entwickler?

![](img/survey_2015.png)

Quelle: https://insights.stackoverflow.com/survey/2015

![](img/survey_2018.png)

Quelle: https://insights.stackoverflow.com/survey/2018


### Woher kommt Git 

- Linux Community nutzte BitKeeper zur Verwaltung des Kernel Source Codes 
- Durch LizenzÃ¤nderung des Herstellers konnte BitKeeper nicht mehr genutzt werden
- Linus Torvalds wollte ein System, das Ã¤hnlich BitKeeper funktionierte, aber die Nachteile der anderen Systeme nicht mehr aufwies (z.B: lange Zeiten bei Branches durch Kopieren aller Dateien)
- Innerhalb weniger Tage wurde die erste Version von Git entwickelt:
- 3. April 2005 AnkÃ¼ndigung des Projektes 
- 7. April 2005 Self-Hosting des Projektes 
- 16. Juni 2005 Linux 2.6 Kernel wurde durch Git verwaltet 
 
### Git Grundlagen

- _Git Repository_: Vereinefacht, ein Verzeichnis, in dem die Dateien â€œÃ¼berwachtâ€ werden
- Metadaten (einschl. der Historie) werden in einem versteckten Unterverzeichnis (.git) verwaltet.
- Git ist eine verteilte Versionsverwaltung
- Keine Notwendigkeit eines zentralen Repositories 
- â€Clonenâ€œ bzw. â€Forkenâ€œ eines Repositories legt eine vollstÃ¤ndige Kopie an. Ã„nderungen kÃ¶nnen dann in das ursprÃ¼ngliche Repository zurÃ¼ckgefÃ¼hrt ( engl. merge) werden. 

### Git Dateistatus

![](img/git_dateistatus.png)

### NÃ¼tzliches fÃ¼r den Einstieg

Lokale Ã„nderungen anzeigen (engl. unstaged changes): `git diff [dateiname]`

Ã„nderungshistorie: `git log` fÃ¼r Commits, `git â€“p log` fÃ¼r ein Preview

Checkout: Der Checkout einer frÃ¼heren Version eines Repositories ersetzt alle Dateien mit dieser Version (time travel)

Branches: Alle Ã„nderungen werden in dem Branch (dt. Zweig) gespeichert ohne den Hauptzweig (engl. master branch) zu beeinflussen (â€kaputt zu machenâ€œ)

Remote: â€œEntfernteâ€œ Kopie eines Repositories (z.B: GitLab, GitHub) â€“ Achtung: Selbst auf GitLab/GitHub ist nicht das zentrale 
Repository, sondern nur eine entfernte Kopie z.B. mit `git push`, `git pull`

Stash: Ã„nderungen, die noch nicht "comitted" wurden, kÃ¶nnen mit `git stash` â€zwischengespeichertâ€œ und mit `git stash apply` wieder hergestellt werden

Fork: Server-seitiger Clone eines Repositories

### Git Workflows 

Trotzdem oder gerade wegen der verteilten Verwaltung kann so einiges schief gehen, daher gilt

![](img/git_one_does_not.jpg)

Verschieden AnsÃ¤tze fÃ¼r Git Workflows

- Centralized Workflow
- Feature Branch Workflow
- Gitflow
- Fork & Merge
- Microsoft Git Branching Strategy  

### WeiterfÃ¼hrendes Material 

- Git Command-line Tool: https://github.com/nschneid/git-command-overview
- GitHub: https://github.com/
- GitLab: https://about.gitlab.com/ 
- The case for Git in 2015: http://www.netinstructions.com/the-case-for-git/
- Pro Git Book: http://git-scm.com/book
- Udacity Kurs*): https://www.udacity.com/course/version-control-with-git--ud123
- Git Userâ€˜s Manual: http://schacon.github.com/git/user-manual.html
- Git â€“ SVN Crashcourse: http://git.or.cz/course/svn.html
- Learn Git in Y minutes: https://learnxinyminutes.com/docs/git/ 
- Coding Blocks Podcast: Comparing Git Workflows: https://www.codingblocks.net/podcast/comparing-git-workflows/ 
- Gitflow Cheatsheet: https://danielkummer.github.io/git-flow-cheatsheet/ 
- Gitflow: https://nvie.com/posts/a-successful-git-branching-model/ 
- Atlassianâ€˜s Gitflow Zusammenfassung:https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow
- Microsoft Recommendation: https://docs.microsoft.com/en-us/azure/devops/repos/git/git-branching-guidance?view=azure-devops&viewFallbackFrom=vsts
- Git Workflows: http://drincruz.github.io/slides/git-workflow-comparison/#/8 
- Git SpielÂ Oh my Git!Â :Â https://ohmygit.org/
- Auschecken von Commits:Â https://www.git-tower.com/learn/git/faq/git-checkout-commits/
- Wenn was schief geht: https://ohshitgit.com/ 

## Virtualisierung  

### Prozesse und Prozess API 

#### Lernziele und Kompetenzen

* **Verstehen** wie sich Prozesse zusammensetzen und Prozesse vom Betriebssystem verwaltet werden.
* **Verstehen** wie Prozesse im Betriebssystem gesteuert werden

#### Definition Prozess

**Â»Vereinfachte DefinitionÂ«: Prozess**

Ein ausgefÃ¼hrtes bzw. laufendes Programm

![](img/os.01.taskmng1.png)



#### Programme

Was ist Ã¼berhaupt ein Programm?

    * Besteht aus Code (Bits) und ggf. statischen Daten
    * Wartet auf der Festplatte und tut nichts
    * Erst durch die AusfÃ¼hrung wird ein Programm zum Prozess

Was benÃ¶tigt ein Programm?

    * BenÃ¶tigt zur AusfÃ¼hrung eine CPU 
    * BenÃ¶tigt fÃ¼r den auszufÃ¼hrenden Code und die Daten Speicher 

#### Illusion

**Frage:** Wie kann die Illusion vieler CPUs geschaffen werden, wenn es nur eine (oder wenige) physikalische CPUs gibt?

Beispiel rechts: Windows Task Manager mit 262 Prozesse 

![](img/os.01.taskmng2.png)

#### Beispiel: Linux *top*

![](img/os.01.top.png)

#### Was ist Virtualisierung? 

* Wir geben jedem Prozess die CPU fÃ¼r eine kurze Zeitspanne 
* Dieses sog. Â»TimesharingÂ« erzeugt eine Illusion mehrerer CPUs
* Konsequenz: Programm lÃ¤uft langsamer, da die CPU Â»geteiltÂ« wird 

**Das ist Â»sehr vereinfachtÂ« Virtualisierung**

#### Was wird fÃ¼r Virtualisierung benÃ¶tigt?

Â»Low Level MachineryÂ« 

    * Methoden und Protokolle fÃ¼r die grundlegende FunktionalitÃ¤t 

Â»High Level IntelligenceÂ«

    * Irgendetwas Geschicktes zum Stoppen und Starten von Programmen 
    * ZusÃ¤tzliches Regelwerk (engl. policies)
    * Regeln wie viele Prozesse auf einer CPU ausgefÃ¼hrt werden dÃ¼rfen
    * Jemand oder etwas, der bzw. das steuert, welcher Prozess als nÃ¤chstes ausgefÃ¼hrt wird

#### Abstraktion von Prozessen

Prozesse bestehen grundlegend aus

* Speicher, in dem die Programmanweisungen bzw. Instruktionen (engl. instructions) liegen
* Speicher, in dem die Daten geschrieben werden 
* Vom Prozess adressierbarer Speicher (engl. address space)
* Registern - Instruktionen lesen und schreiben in Register, dies ist notwendig fÃ¼r die AusfÃ¼hrung d. Prozesses

    **Diese Informationen kÃ¶nnen jederzeit Â»weggespeichertÂ« und wiederhergestellt werden**

#### Spezielle Register, die benÃ¶tigt werden

Program Counter (Abk. PC) oder auch Instruction Counter (Abk. IC)

* Hier steht die nÃ¤chste Anweisung, die ausgefÃ¼hrt werden soll

* Stack Pointer, Frame Pointer, Funktionsparameter, lokale Variablen und RÃ¼cksprungadressen (engl. return address) - mehr dazu spÃ¤ter

Register fÃ¼r I/O-Informationen

* Liste der Dateien, die der Prozess aktuell geÃ¶ffnet hat  

#### Prozess-API 

AuÃŸerdem benÃ¶tigen wir eine Programmierschnittstelle (engl. process api), die jedes Betriebssystem beinhalten muss (wird spÃ¤ter noch weiter vertieft)

* `create`: AusgewÃ¤hltes Programm wird gestartet und ein neuer Prozess erzeugt 
* `destroy`: Falls sich ein Programm nicht von selbst beendet, ist dies sehr hilfreich
* `wait`: Durchaus sinnvoll zu warten, bis ein Prozess von selbst aufhÃ¶rt zu laufen
* `status`: Statusinformation von Prozessen abfragen 

Weitere MÃ¶glichkeiten sind je nach Betriebssystem unterschiedlich, z.B.:
`suspend` und `resume` um Prozesse anzuhalten und weiterlaufen zu lassen

#### Wie wird ein Prozess erzeugt?

1. Voraussetzung: Ein Programm muss in ausfÃ¼hrbarer Form vorliegen (mehr dazu spÃ¤ter)
2. Programm und statische Daten werden in den Adressraum des Prozesses geladen
    * Â»FrÃ¼herÂ« wurde das gesamte Programm in den Speicher geladen (engl. eagerly)
    * Â»HeuteÂ« wird nur der benÃ¶tigte Programm-Code und die erforderlichen Daten geladen (engl. lazy)  

        Um dieses sog. Â»Lazy LoadingÂ« zu verstehen, werden wir uns spÃ¤ter noch mit Â»PagingÂ« und Â»SwappingÂ« befassen mÃ¼ssen
3. Der sog. Â»StackÂ« bzw. Â»Runtime StackÂ« wird zugewiesen
    * C nutzt den Stack fÃ¼r lokale Variablen, Funktionsparameter und RÃ¼cksprungadressen
4. Das Betriebssystem fÃ¼llt z.B. die Parameterlisten
    * Bei C sind dies `argc` und `argv`, so dass das Programm (hier die `main`-Funktion) auf die Werte zugreifen kann[^4]
    * Kennen Sie auch aus Java
5. Nun wird noch der Heap reserviert 
    * In C fÃ¼r dynamischen Speicherzuordnung via `malloc()` und `free()`
    * Exkurs: Memoryleaks baut man Ã¼brigens, indem man in C vergisst `free()` aufzurufen

![](img/os.01.processcreation.png)

6. Das Betriebssystem unterstÃ¼tz nun den Prozess, indem es z.B. dem Prozess mehr Speicher gibt, wenn der Heap vergrÃ¶ÃŸert werden muss 
7. Nun  werden noch Input/Output-Resourcen erzeugt (sie ahnen es, spÃ¤ter mehr dazu)

    * Unter UNIX sind dies die drei sog. Â»File DescriptorsÂ« (https://sites.ualberta.ca/dept/chemeng/AIX-43/share/man/info/C/a_doc_lib/aixuser/usrosdev/std_input_output.htm)
        * Standard Input, 
        * Standard Output und 
        * Standard Error Output

#### Prozess Status

Was bedeuten eigentlich die Status...?

* Laufend
* Schlafend 
* Gestoppt
* Zombie

> Tasks shown as running should be more properly thought of as 'ready to run' -- their task_struct is simply represented on the Linux run-queue. Even without a true SMP machine, you may see numerous tasks in this state depending on top's delay interval and nice value.

Quelle: https://man7.org/linux/man-pages/man1/top.1.html

#### Prozessstatus & mÃ¶gliche StatusÃ¼bergÃ¤nge


* **Running:** Prozess lÃ¤uft auf einer CPU 
* **Ready:** Prozess kÃ¶nnte laufen, aber das OS hat entschieden, den Prozess noch nicht laufen zu lassen
* **Blocked:** Prozess hat eine Aktion ausgefÃ¼hrt, die erst abgeschlossen werden kann, wenn ein anderes Ereignis stattgefunden hat - typischerweise handelt es sich hierbei um eine I/O-Operation

    Ist ein Prozess geblockt, wartet das Betriebssystem auf die I/O-Operation, um dann den Prozess wieder in den Status *Ready* zu verschieben. 

 ![](img/os.01.status.png)

#### Ein kleines Problem 

Wer entscheidet eigentlich welcher Prozess als nÃ¤chster gestartet wird?

Der sog. Â»SchedulerÂ« trifft diese Entscheidung (spÃ¤ter mehr dazu)

Bevor wir uns den Scheduler anschauen, mÃ¼ssen wir uns allerdings noch ein paar weitere Gedanken Ã¼ber Prozesse machenâ€¦ 

#### Ein paar Gedanken zu Prozessen 

Wir benÃ¶tigen
* Eine Datenstruktur fÃ¼r Prozesse 
* Eine Liste aller Prozesse
* Eine Liste aller blockierten Prozesse
* Eine MÃ¶glichkeit Register bei Stoppen wegzuspeichern und beim Anlaufen des Prozesses wieder zu laden (engl. context switch)

Und was passiert eigentlich, wenn ein Prozess beendet ist, aber noch nicht alles Â»aufgerÃ¤umtÂ« wurde? 

In UNIX-Systemen haben solche Prozesse einen eigenen Status: **Zombie** 

#### Exkurs: Datenstruktur von xv6-Prozessen

Alle Informationen Ã¼ber einen Prozess stehen in einem Prozesskontrollblock (engl. process control block, kurz PCB) 

![](img/os.01.pcb.png)

#### Zusammenfassung

* Prozesse sind die grundlegende Abstraktion eines Programmes
* Zu jedem Zeitpunkt kann ein Prozess Ã¼ber seinen Status, den Speicherinhalt, seinen Adressraums, den Inhalt der CPU-Register (einschl. program counter und stack pointer) und den I/O-Informationen (d.h. geÃ¶ffnete Dateien) beschrieben werden
* Die Prozess-API besteht aus Aufrufen, die in Zusammenhang mit Prozessen ausgefÃ¼hrt werden kÃ¶nnen, z.B. zum Erzeugen oder Beenden von Prozessen
* Unterschiedliche Ereignisse fÃ¼hren zu StatusÃ¤nderungen im Prozess (z.B. der Aufruf einer blockierenden I/O-Operation)
* Eine Prozessliste enthÃ¤lt alle Informationen Ã¼ber die Prozesse auf einem System

#### Wiederholungsfragen Prozesse und Prozess-API 

##### Welche Status von Prozessen haben Sie kennen gelernt? 

- [[x]] Laufend
- [[ ]] Wartend
- [[x]] Schlafend
- [[x]] Gestoppt
- [[ ]] Vampir
- [[x]] Zombie

#### WeiterfÃ¼hrende Informationen 

- Windows-Prozesse mit PowerShell anzeigen, auslesen und beenden: https://www.scriptrunner.com/de/blog/windows-prozesse-mit-powershell-anzeigen-auslesen-und-beenden/ 

## Virtualisierung Teil 2
###  Direct Execution 

### Lernziele und Kompetenzen

* **Verstehen** wie Prozesse im Betriebssystem gesteuert werden
* **Verstehen** welche Probleme bei der direkten AusfÃ¼hrung von Prozessen auf der CPU entstehen und wie dem im Betriebssystem begegnet wird

### Problem

Bisher haben wir gelernt, dass es Prozesse gibt, diese irgendwie gestartet werden kÃ¶nnen.

Das Betriebssystem lÃ¤dt also ein Programm, lÃ¤dt alle Register und startet den Prozess... 

* **Frage 1:** Wie stellen wir sicher, dass der Prozess nichts Â»VerbotenesÂ« tut?

* **Frage 2:** Die direkte AusfÃ¼hrung des Prozesses auf der CPU (engl. direct execution) ist zwar schnell, aber was passiert nun, wenn der Prozess eingeschrÃ¤nkte Aktionen durchfÃ¼hren will (z.B. mehr Speicher, I/O-Operation etc.)?

* **Frage 3:** Und wie stellen wir Ã¼berhaupt sicher, dass der Prozess die Kontrolle wieder abgibt? Solange der Prozess ausgefÃ¼hrt wird, hat das Betriebssystem ja keine Kontrolle Ã¼ber die CPU... ğŸ¤”

### LÃ¶sungsidee

Programme laufen im sog. **Â»User Mode LinuxÂ«** oder allgemein **Â»User ModeÂ«**. 

* Es wird eingeschrÃ¤nkt, was das Programm Â»tunÂ« kann
* Z.b. werden I/O-Operationen eingeschrÃ¤nkt
* Wenn ein Programm versucht etwas unerlaubtes auszufÃ¼hren wird eine Â»ExceptionÂ« im Prozessor erzeugt (das heiÃŸt tatsÃ¤chlich so, hat aber nichts z.B. mit Java Exceptions zu tun)

Der Gegensatz: **Â»Kernel ModeÂ«**

* Hier sind alle Operationen, auch bzw. insbesondere I/O-Operationen erlaubt

### System Call 

Wenn ein Programm im *User Mode* etwas ausfÃ¼hren mÃ¶chte, das eigentlich untersagt ist, fÃ¼hrt es einen sog. Â»System CallÂ« oder kurz Â»SyscallÂ« aus.

* System Calls werden von allen modernen Betriebssystemen angeboten
* POSIX-Systeme (Portable Operating System Interface[^1]) bieten mehrere hundert solcher System Calls an 


[^1]: https://standards.ieee.org/project/1003_1.html#Standard



#### System Call Ablauf

Das Programm... 
* FÃ¼hrt ein sog. Trap-Instruktion aus
* Springt in Kernel und startet im privilegierten Modus (Kernel Modus)
* FÃ¼hrt die Operationen aus, die im Â»System Call HandlerÂ« hinterlegt sind
* FÃ¼hrt eine sog. Return-From-Trap-Instruktion aus
* Kehrt in den User Mode zurÃ¼ck

### Vorsicht

Die Hardware muss darauf achten â€genÃ¼gend Bestandteile vom Programm bestehen zu lassenâ€œ, so dass es spÃ¤ter wieder ausgefÃ¼hrt werden kann.

Am Beispiel des x86: 

Hier werden...

* Program Counter, Flags und weitere Register in einen sog. Per-Process-Kernel-Stack Â»gepushtÂ« (Datenstruktur Stack klar? Ggf. Exkurs am Ende)
* Bei der Return-From-Trap-Instruktion werden diese wieder vom Stack geladen
* Danach kann das Programm wieder im User Mode ausgefÃ¼hrt werden

Dieses Vorgehen wird von Betriebssystem zu Betriebssystem zwar unterschiedlich gehandhabt, ist im Grundsatz aber immer Ã¤hnlich

### Nochmal Vorsicht 

**Frage:** Woher weiÃŸ das OS, welcher Code fÃ¼r System Calls ausgefÃ¼hrt werden soll?

Das Programm kann ja kein Speicherbereich angeben

GrundsÃ¤tzlich wÃ¤re das auch eine sehr schlechte Ideeâ€¦ Das ist schon klar warum , oder?

### Trap Table 

**LÃ¶sung:** 

* Es wird eine sog. Â»Trap TableÂ« zur Boot-Zeit erstellt
* Beim Booten ist das System immer im Kernel Mode
* Das Betriebssystem kann der Hardware somit sagen, welcher Code bei welchem Ereignis ausgefÃ¼hrt wird 
* Das Betriebssystem informiert die Hardware Ã¼ber diese sog. Trap Handlers oder System Call Handlers

Nur mal so... Was kÃ¶nnte man denn machen, wenn man eine eigene Trap Table installieren kÃ¶nnte? ğŸ¤”

### Zusammenfassung

* Prozesse direkt (d.h. ohne Kontrolle) auf der Hardware auszufÃ¼hren, ist keine gute Idee 
* Prozesse werden im User Mode ausgefÃ¼hrt und sind eingeschrÃ¤nkt was bestimmte Aktionen angeht 
* Mittels System Calls kann ein Prozess spezielle Aktionen ausfÃ¼hren (lassen), die jedoch vom Betriebssystem kontrolliert werden
* Eine Trap Table enthÃ¤lt die Information darÃ¼ber, wo der Code steht, der durch ein System Call ausgefÃ¼hrt wird 
* Trap Tables werden zur Boot-Zeit (im Kernel Modus) erzeugt


## Scheduler  Teil 1

### CPU-Scheduling 

### Wiederholung

* Direct Execution

    * Weshalb ist es keine gute Idee, Prozesse direkt auszufÃ¼hren? 

* SysCalls

  * Woher weiÃŸ die Hardware, welcher Betriebssystem-Code ausgefÃ¼hrt werden soll?  
  * Wie lÃ¤sst sich dies als Angriffsvektor nutzen?

* Stack

    * Wie ist die grundlegende Funktionsweise eines Stacks?

### Lernziele und Kompetenzen

* Grundlagen der Scheduling-Mechanismen **kennen lernen** 
* **Verstehen** wie Prozesse von Betriebssystemen Â»gescheduledÂ« werden kÃ¶nnen

### Eine kurze Wiederholung

Bisher kennen gelernt:

* Â»Low-Level-MechanismenÂ« von laufenden Prozessen (z.B. Context Switch)
* Falls nicht klar, Einheit 1 wiederholen + Kapitel 4-6 aus *Operating Systems: Three Easy Pieces*[^1] wiederholen

Was fehlt noch? 

* Wann darf welcher Prozess laufen (engl. scheduling)

[^1]: http://pages.cs.wisc.edu/~remzi/OSTEP/

### Scheduling Policy

* Die Â»Scheduling PolicyÂ« (also das Regelwerk) hÃ¤ngt vorrangig vom Â»WorkloadÂ« der Prozesse ab
* Zur Vereinfachung werden zunÃ¤chst folgende (absolut unrealistische) Annahmen getroffen:

  * Jeder Job lÃ¤uft gleich lang
  * Alle Jobs treffen zur gleichen Zeit ein
  * Einmal gestartet, lÃ¤uft ein Job bis er beendet ist
  * Alle Jobs verwenden ausschlieÃŸlich die CPU
  * Laufzeit (engl. runtime) eines jeden Jobs ist bekannt

---

### Scheduler Metriken: Turnaround-Zeit


* Hinweis: Metriken werden im 3. Semester in SEKS vertieft 
* FÃ¼r heute genÃ¼gt: Metrik = einfach um etwas zu messen
* FÃ¼r uns: zunÃ¤chst nur eine Metrik

$$
T_{turnaround}=T_{completion}-T_{arrival}
$$

Aufgrund unserer vorherigen Annahmen gelten

* Alle Jobs kommen zum  gleichen Zeitpunkt an: $T_{arrival} = 0$
* Somit gilt: $T_{turnaround}=T_{completion}$

---

### First In, First Out (1)

First in, First out (abk. FIFO) oder manchmal auch First Come, First Serve (abk. FCFS)

* Einfach und daher auch einfach zu implementieren
* Beispiel

  * Jobs A, B und C kommen kurz nacheinander an
  * Jeder Job hat eine Laufzeit von 10 Sekunden
  * Was ist die durchschnittliche Turnaround-Zeit?
  * $\frac{10+20+30}{3}=20$

![](img/os.03.fifo.png)

### First In, First Out (2)

* Heben wir jetzt die erste Annahme auf

  * Zur Erinnerung: Jeder Job lÃ¤uft gleich lang
  * Ab sofort: Jeder Job lÃ¤uft eben nicht mehr gleich lang
  * Gibt es einen Workload, der FIFO Â»alt aussehen lÃ¤sstÂ«?
  * $\frac{100+110+120}{3}=110$

![](img/os.03.fifo_bad.png)


### Convoy Effect (dt. Konvoieffekt)

* Kennt jeder
* Mehrere Kunden mit wenigen Waren warten hinter einem einzigen Kunden mit vielen Waren 
* Nur eine Supermarktkasse offen... ğŸ˜¤

![](img/os.03.convoy.jpg)[^2]

[^2]: Photo by Paul Townsend, licensed under Attribution-ShareAlike 2.0 Generic (CC BY-SA 2.0)

### Shortest Job First

* Shortest Job first (Abk. SJF)
* Beschreibt die Policy recht treffend 

    * FÃ¼hrt den kÃ¼rzesten Job aus, dann den zweit kÃ¼rzesten etc.

* Beispiel von zuvor

    * SJF reduziert Turnaround-Zeit von 110 auf 50 

* $\frac{10+20+120}{3}=50$

![](img/os.03.sjf.png)

### Problem bei SJF

* LÃ¶sen wir ab jetzt die Restriktion, dass alle Jobs zum selben Zeitpunkt eintreffen
* Beispiel: A trifft bei $ğ‘¡=0$, B und C bei $ğ‘¡ = 10$ ein
* Turnaround-Zeit hat sich hierdurch verdoppelt
* $\frac{100+(110-10)+(120-10)}{3}=103,33$

![](img/os.03.sjf_bad.png)

### Exkurs: Non-Preemptive vs. Preemptive 

* Non-Preemptive 

    * Stammt aus den Zeiten von sog. Batch-Systemen
    * Jeder Job wurde zu Ende gerechnet, bevor Ã¼berhaupt in ErwÃ¤gung gezogen wurde einen anderen Job zu starten 

* Preemptive

    * Alle modernen Betriebssysteme sind Â»preemptiveÂ«
    * Jederzeit gewillt einen Job zu stoppen und einen anderen dafÃ¼r zu starten
    * Nutzen den zuvor behandelten Context Switch

### Shortest Time-to-Completion First (STCF)

* SJF ist non-preemptive â–¶ versuchen wir es preemptive
* LÃ¶sen wir nun die Restriktion, dass alle Jobs bis zum Ende durchlaufen 
* Jedes Mal wenn ein Job eintrifft, wird derjenige der die geringste Restlaufzeit
* **Achtung!** Das geht nur wegen unserer letzten noch bestehenden Annahme: Die (Rest-)Laufzeit ist bekannt! 

* $\frac{(120-0)+(20-10)+(30-10)}{3}=50$

![](img/os.03.stcf.png)[^3]

[^3]: Bild von Gerd Altmann auf Pixabay

### Problem mit STCF

* Benutzer wartet bis Job A (z.B. Aktualisierung in Excel o.Ã¤.) fertig ist
* Nun kommt die Hausaufgabe vom letzten Mal ins Spiel: Sie erinnern sich an den Unterschied zwischen Foreground- und Background-Jobs?  
* Was ist denn, wenn andauernd neue kÃ¼rzere Jobs eintreffen, die keine Benutzereingabe erfordernâ€¦ ğŸ¥±

![](img/os.03.wait.jpg)

### Scheduler Metriken: Antwortzeit

* Zweite Metrik fÃ¼r heute: Antwortzeit (eng. response time)
* Dauer vom Zeitpunkt an dem Job eintrifft bis er das erste Mal Â»gescheduledÂ« wird
* $\frac{0 + 5 + 10}{3}=5$

$$
T_{response}=T_{firstrun}-T_{arrival}
$$

![](img/os.03.sjf_responsetime.png)

### Round Robin (RR)

* Grundprinzip: Jeder Job wird nur fÃ¼r eine bestimmte Zeitspanne (engl. time slice) ausgefÃ¼hrt 
* Zeitscheibe ist ein Vielfaches vom Timer Interrupt (d.h. bei einem Timer Interrupt von 10ms ein Vielfaches von 10)
* Durchschnittliche Antwortzeit im Vergleich zu SJF (vorherige Folie) ist 1
* $\frac{0 + 1 + 2}{3}=1$

![](img/os.03.rr_responsetime.png)

### Round Robin (Forts.)

* Der Context Switch kostet Ressourcen
* D.h. wie lange mÃ¼ssten die Time Slices sein, dass sich ein Context Switch Ã¼berhaupt lohnt?
* FÃ¼r Antwortzeit hervorragend geeignet, fÃ¼r Turnaround-Zeit Ã¼berhaupt nicht
* Round Robin zieht AusfÃ¼hrungsdauer in die LÃ¤nge, in manchen FÃ¤llen ist die AusfÃ¼hrung sogar schlechter als FIFO  
* Allgemein lÃ¤sst sich festhalten: Jede Policy die fair ist, d.h. die CPU auf Prozesse aufteilt, fÃ¼hrt zu einem schlechten Ergebnis in Bezug auf Turnaround-Zeit 

---

### Kurzer Zwischenstand

* Wir haben zwei Typen von Schedulern kennen gelernt 

    * SJF/STCF optimiert Turnaround-Zeiten, ist jedoch ungÃ¼nstig fÃ¼r Antwortzeiten 
    * RR optimiert die Antwortzeit, ist aber ungÃ¼nstig fÃ¼r die Turnaround-Zeit

* Es gibt noch zwei Annahmen/Restriktionen, die Â»aufgelÃ¶stÂ« werden mÃ¼ssen

    4. Alle Jobs verwenden ausschlieÃŸlich die CPU
    5. Laufzeit eines jedes Jobs ist bekannt

---

### Input/Output

* LÃ¶sen wir die nÃ¤chste Restriktion: Ab sofort kÃ¶nnen Jobs auch I/O-Operationen aufrufen
* Scheduler muss nun entscheiden wann eine I/O-Operation durchgefÃ¼hrt wird, da in der Zeit der laufende Prozess die CPU nicht nutzen kann und sich somit im Status Â»blockedÂ« befindet
* Scheduler kann demnach in dieser Zeit einen anderen Job laufen lassen
* Ist die I/O-Operation fertig (wird Ã¼ber Interrupt angezeigt), wird der zuvor geblockte Job wieder auf Â»readyÂ« gesetzt
* Ab jetzt kann er Job potentiell wieder laufen

### Overlapping

* Schlechte Ressourcen-Nutzung
![](img/os.03.schechte_ressourcennutzung.png)

* Bessere Ressourcen-Nutzung dank Overlapping
![](img/os.03.overlapping.png)

### Kein Wissen Ã¼ber Prozessdauer

* Als letzte Restriktion lÃ¶sen wir nun die Kenntnisse Ã¼ber die Prozesslaufzeit auf 
* D.h. der Scheduler weiÃŸ nichts Ã¼ber die Restlaufzeit eines Prozesses
* Wie kann dann sinnvoll gescheduled werden? 

LÃ¶sungsidee: sog. Â»Multi-Level Feedback QueueÂ«-AnsÃ¤tze verwenden die nahe Vergangenheit, um die Zukunft vorauszusagen! ğŸ¤©

## Scheduler Teil 2 

### Multi-Level Feedback Queue

### Lernziele und Kompetenzen

* Grundlagen des Scheduling-Verfahrens mit Multi-Level Feedback Queues **kennen lernen** 

### Wiederholung

* Zuletzt wurde die Annahme fallen gelassen, dass wir die Laufzeit eines Prozesses im Vorhinein wissen
* Wie kann ohne diese Kenntnisse ein Scheduler gebaut werden, er sowohl Antwortzeiten (z.B. fÃ¼r interaktive Anwendungen) als auch die Turnaround-Zeiten (d.h. ein Job mÃ¶glichst schnell fertig stellen) ohne Wissen Ã¼ber die Laufzeit eines Prozesses minimiert?

### LÃ¶sungsidee: Multi Level Feedback Queue (MLFQ)

Grundlegende Regeln

* MLFQ hat mehrere Queues, jede mit einem PrioritÃ¤ts-Level
* Jobs mit hÃ¶herer PrioritÃ¤t laufen zuerst (=hÃ¶here Queue)
* Falls sich mehrere Jobs in der gleichen Queue befinden gilt:

  * Regel 1: `If Priority(A) > Priority(B), A runs (B doesnâ€˜t)`
  * Regel 2: `If Priority(A) == Priority(B), A & B run in Round Robin`

* Wie wird jedoch die PrioritÃ¤t fÃ¼r ein Job festgelegt?

  * PrioritÃ¤t  nicht fix, sondern hÃ¤ngt vom **beobachteten Verhalten** des Jobs ab

* Wenn die ganze CPU-Zeit auf A und B verteilt wird, wie kommen dann aber C und D zum Zug? 

### MLFQ Beispiel

![](img/os.04.mlfq.png)

### 1. Versuch - PrioritÃ¤ten Ã¤ndern

* Workload Betrachtung: Mischung aus...

  * interaktiven Jobs, die kurz laufen, geben CPU schnell wieder frei und
  * langlaufende Jobs, die die CPU-intensiv in Anspruch nehmen, aber deren Antwortzeit Â»nicht relevantÂ« ist. 

* ZusÃ¤tzliche Regeln:

  * Regel 3: Ein neu eintreffender Job erhÃ¤lt immer die hÃ¶chste PrioritÃ¤t (oberste Queue)
  * Regel 4a: Wenn ein Job die gesamte Zeitscheibe aufbraucht, wird seine PrioritÃ¤t herabgestuft (d.h. eine Queue nach unten geschoben)
  * Regel 4b: Wenn ein Job die CPU vor Ablauf der Zeitscheibe freigibt, bleibt er auf der gleichen PrioritÃ¤t (d.h. bleibt in der aktuellen Queue)

### Beispiel 1: Ein langlaufender job 

* Job lÃ¤uft immer bis ans Ende der Time Slice 
* Nach jeder Time Slice wird der Job heruntergestuft
* Am Ende lÃ¤uft der Job auf der niedrigsten PrioritÃ¤t

![](img/os.04.one_sad_job.png)


### Beispiel 2: Ein zusÃ¤tzlicher Â»KurzlÃ¤uferÂ«

* Bei $ğ‘‡ = 100$ trifft ein zweiter, kurzlaufender Job ein
* MLFQ trifft immer die Annahme, dass ein neuer Job ein Â»KurzlÃ¤uferÂ« ist 

![](img/os.04.kurzlaeufer.png)


### Beispiel 3: ZusÃ¤tzliche I/O

* Mischung aus I/O-intensivem und CPU-intensivem Job
* Nach Regel 4 bleibt der Job, der die CPU schnell freigibt, weil er z.B. auf die Tastatur wartet, hoch priorisiert
* Wer sieht denn das Problem?

![](img/os.04.io.png)


### Game the Scheduler

* Programm so schreiben, dass es kurz vor Ablauf der Zeitscheibe einen Dateizugriff ausfÃ¼hrt (die Datei selbst ist uns komplett egal)
* Programm bleibt hoch priorisiert, da Zeitscheibe nicht vollstÃ¤ndig aufgebraucht
* Machen wir das immer bei â‰ˆ 99% der Zeitscheibe, kÃ¶nnten wir die CPU 99% Ã¼bernehmen
* Langlaufende Jobs bleiben auf der Strecke (engl. starvation)
* Job A kommt nie mehr in eine bessere Queue, selbst wenn sich sein Verhalten Ã¤ndert 


### Game the Scheduler

Wie kÃ¶nnten wir das besser machen?

![](img/os.04.game_the_scheduler.png)

---

### Versuch 2: Priority Boost

* Neue Regel
    
    * Regel 5: Nach definierten Zeit *s* werden alle Jobs wieder in die oberste Queue verschoben

* Regel 5 lÃ¶st zwei Probleme:

    * Prozesse laufen nicht mehr Gefahr der Â»StarvationÂ«
    * Wenn ein Job Â»plÃ¶tzlichÂ« interaktiv wÃ¼rde, kann er entsprechend priorisiert werden (s. nÃ¤chste Seite)

### Voodoo Constant 

Spannende Frage: Wie lange sollte die Zeitspanne *s* sein?

* Der Wert *s* heiÃŸt nach John Ousterhout Â»Voodoo ConstantÂ«.
* FÃ¼r die Bestimmung sog. Voodoo-Konstanten benÃ¶tigt das System etwas Â»schwarze MagieÂ« zu deren Bestimmung
* Dilemma: Wenn *s* zu groÃŸ gewÃ¤hlt wird, kÃ¶nnen CPU-intensive Jobs doch verhungern, ist sie zu klein gewÃ¤hlt bekommen interaktive Jobs nicht genÃ¼gend CPU  
* Generell sollten Voodoo-Konstanten vermieden werden (Ousterhout's Law)


### Versuch 3: Verbesserte BuchfÃ¼hrung

* Problem: Regel 4a und 4b ermÃ¶glichen immer noch, dass der Scheduler ausgespielt wird 
* LÃ¶sungsidee: Eine verbesserte BuchfÃ¼hrung
* Merken wie viel Zeit ein Prozess in einer Queue verbracht hat
* Sobald ein Prozess kumuliert eine Zeitscheibe aufgebraucht hat, wandert er eine Queue nach unten
* Aus den Regeln 4a und 4b wird
  * Regel 4: Sobald ein Job seine gesamte Zeit auf einer PrioritÃ¤tsebene genutzte hat (ungeachtet dessen, wie viel Zeit er der CPU  Â»zurÃ¼ck gibtÂ«), wird seine PrioritÃ¤t reduziert (d.h. er wandert eine Queue nach unten). 

### Tuning und MLFQ Probleme 

* Wie sollte MLFQ priorisiert werden?
* Wie viele Queues 
* Wie groÃŸ sollte die Zeitspanne (engl. time slice) pro Queue sein?
* Machen unterschiedliche Time Slices pro Queue Sinn?
* Wie oft findet Priority Boost statt?

### MLFQ Regeln 

* **R 1**: If Priority(A) > Priority(B), A runs (B doesnâ€™t)
* **R 2**: If Priority(A) = Priority(B), A & B run in round-robin fashion using the time slice (quantum length) of the given queue.
* **R 3**: When a job enters the system, it is placed at the highest priority (the topmost queue).
* **R 4**: Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).
* **R 5**: After some time period *s*, move all the jobs in the system to the topmost queue. 

### Wird MLFQ Ã¼berhaupt irgendwo verwendet?

* Solaris

  * MLFQ *Time-Sharing Scheduling Class* wird Ã¼ber eine Reihe von Tabellen konfiguriert
  * Diese kÃ¶nnen durch einen Admin angepasst werden ğŸ˜±
  * 60 Queues, mit langsam steigenden Time Slices von 20 ms bis zu 1 Sekunde 

* FreeBSD 

  * Scheduler nutzt Formel um PrioritÃ¤t eines Jobs zu berechnen
  * Wie viel CPU hat der Prozess schon verbraucht + wie ist  der Verbrauch abgefallen (sog. Decay-Usage Algorithms)

### Be Nice 

* Unix Betriebssysteme nehmen Â»HinweiseÂ« von Nutzern und Administratoren bzgl. der Priorisierung von Jobs entgegen. 
* Unter Windows kann man beim Start eines Prozesses mittels `start` die PrioritÃ¤t des Prozesses angeben
* Hausaufgabe: Machen Sie sich mit dem Befehl `nice` (Linux) und `start` (Windows) vertraut

![](img/os.04.benice.png)


---

marp: true
theme: defalut
paginate: true
footer: 

---
<style>
img[alt~="center"] {
  display: block;
  margin: 0 auto;
}
</style>

## Scheduler Teil 3

### Lottery Scheduling

### Lernziele und Kompetenzen

* Grundlagen des Lottery-Scheduling-Verfahrens **kennen lernen** 

### Proportional / Fair Share Scheduler

* Anstelle Turnaround-Zeiten zu optimieren, versuchen Fair Share Scheduler sicherzustellen, dass jeder Job einen gewissen Prozentsatz der CPU-Ressourcen erhÃ¤lt

* Beispiel: Lottery Scheduling
* Grundidee: Es werden Tickets vergeben, die wie in einer Lotterie gezogen werden
* Prozesse, die Ã¶fters laufen sollen, erhalten schlicht mehr Lotterieloseâ€¦ 

Einfach, oder? ğŸ¤”

### Grundkonzept: Tickets represent your share

* Grundlegendes Konzept: Es werden Tickets vergeben (entsprechen einem CPU Share)
* Beispiel:

  * Job A erhÃ¤lt 75% der Tickets (hier: Lose 0..74)
  * Job B erhÃ¤lt  25%  der Tickets (hier: Lose 75..99)
  * Scheduler muss nun wissen, wie viele Lose es insgesamt gibt (hier: 100)
  * Gewinnerticket gibt an, welcher Prozess lÃ¤uft

![](img/os.05.tickets.png)


### Lottery Scheduler - Ãœberlegungen

* Statistische AnnÃ¤herung an gewÃ¼nschte Aufteilung 
* Je lÃ¤nger die Jobs laufen, desto besser ist die AnnÃ¤herung 
* Was ist bei einer Verteilung 99% zu 1%?
* Man benÃ¶tigt einen guten Zufallsgenerator
* Was macht man wenn ein neuer Job dazu kommt? 


### Ticket WÃ¤hrung

User mit mehreren Tickets, kann diese einer eigene Â»WÃ¤hrungÂ« zuordnen 

* Beispiel

  * A und B haben je 100 Tickets 
  * A hat zwei Jobs, A1 und A2, jeder Job bekommt 500 (von insg. 1.000) User Tickets in Aâ€˜s WÃ¤hrung 
  * B hat 1 Job B1, dieser bekommt 10 von 10 (User Tickets) in Bâ€˜s WÃ¤hrung
  * System konvertiert Aâ€˜s Tickets pro Job zu je 50 Tickets in der SystemwÃ¤hrung
  * System konvertiert Bâ€˜s Ticktes zu 100 Tickets in SystemwÃ¤hrung

### Ticket Transfer

Prozess kann temporÃ¤r Tickets auf einen anderen Prozess Ã¼bertragen

* Beispiel: 

  * Client-Server Mechanismus (lokal)
  * Client, der eine Anfrage von einem Server wartet, kann seine Tickets dem Server geben, um die Antwort zu beschleunigen 
  * Nach Beendigung gibt der Server die Tickets an den Client zurÃ¼ck 

### Linux Completely Fair Scheduler (CFS)

* Problem: Scheduling kann bis zu 5% der CPU-Ressource ausmachen 
* CFS fÃ¼hrt eine virtual runtime (*vruntime*) ein
* Jeder Prozess, der lÃ¤uft, sammelt *vruntime* an
Bei Scheduling-Entscheidung wÃ¤hlt der Scheduler den Prozess mit der geringsten vruntime aus

### CFS: Wie oft sollte ein Prozess gewechselt werden?

* *sched_latency*

  * Time Slice Dauer, typischerweise 48ms 
  * Wird durch Anzahl der Prozesse *n* geteilt
  * Ergibt die Zeitscheibe pro Prozess
  * Somit ist die Zeitverteilung vollstÃ¤ndig fair 

* *min_granularity*

  * Mindestdauer, typischerweise 6ms
  *  Dieser Wert wird niemals unterschritten (Bsp. 10 Prozesse ergÃ¤be 4,8ms pro Prozess)

* CFS nutzt regelmÃ¤ÃŸige Timer Interrupts, der Scheduler kann Entscheidungen also immer nur zu fixen Zeitpunkten treffen

---

### CFS - Beispiel

* Vier Jobs (A,B,C,D), wobei B, C und D kurz nach A eintreffen
* Nach der ersten Zeitscheibe wird einer der Jobs aus (B,C,D) gewÃ¤hlt da hier vruntime von B, C und D < vruntime von A
* Nach *t = 100* sind C und D fertig, danach wird die vruntime zwischen A und B aufgeteilt 

![](img/os.05.cfs.png)

### CFS - Weighting / Niceness

CFS ermÃ¶glicht die Angabe von PrioritÃ¤ten, damit Prozesse mehr CPU-Ressourcen erhalten kÃ¶nnen. 

* In UNIX entspricht das dem Â»nice levelÂ«
* Kann zwischen -20 und + 19 gesetzt werden
* 0 ist Standardwert
* < 0 hÃ¶here Prio, > 0 kleinere Prio

### CFS: Zeitscheibe berechnen

* Gewichtungen erlauben es die Zeitscheibe pro Prozess zu berechnen:

$$
time\_sclice_k = \frac{weight_k}{\sum\limits_{i=0}^{n}weight_i}\cdot sched\_latency
$$

* Beispiel:

  * 2 Prozesse A (Prio=-5), B (Prio=0)
  * $ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡_ğ´$  = 3121, $ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡_ğµ$=1024    
  * A erhÃ¤lt 36ms, B erhÃ¤lt 12ms

### prio_to_weight

![](img/os.05.prio_to_weight.png)

### CFS: vruntime berechnen

* Berechnet wieviel Laufzeit ein Prozess imVerhÃ¤ltnis zur Gewichtung genutzt hat

$$
vruntime_i = vruntime\cdot \frac{weight_0}{weight_i} \cdot runtime_i
$$

* Hinweis:

  * Gewichtung bleibt im VerhÃ¤ltnis gleich, wenn andere PrioritÃ¤ten gewÃ¤hlt werden
  * Annahme A hat 5 und B hat 10
  * A und B werden noch im selben VerhÃ¤ltnis wie zuvor gescheduled


### CFS Prozesslisten

* Problem: Bei mehreren hundert oder gar 1.000 Prozessen, wie wird der nÃ¤chste Prozess gefunden?
* Kurzes Gedankenspiel: Skalieren Listen? Hier mÃ¼ssten man immer aller linear durchsuchen, was in einem linearen Aufwand von $ğ‘‚(ğ‘›)$ resultiert.  
* LÃ¶sung: Geschickte Wahl der Datenstruktur:

  * CFS speichert Prozesse in Rot-Schwarz-BÃ¤umen (ausgeglichener Baum)
  * Algorithmen auf Rot-Schwarz-BÃ¤umen sind logarithmisch mit einem Aufwand von $ğ‘‚(lğ‘œğ‘”_ğ‘›)$ 

* Deswegen: Algorithmen und Datenstrukturen

### CFS und I/O

* Was passiert eigentlich wenn ein Prozess A permanent lÃ¤uft, weil B aufgrund einer I/O-Operation blockiert (z.B. 10s)?
* B wacht auf und hat die niedrigste vruntime (10s kleiner als bei A)
* B wÃ¼rde nun die CPU fÃ¼r 10s monopolisieren, Â»StarvationÂ« von A wÃ¤re potentiell mÃ¶glich

* LÃ¶sung: CFS setzt die *vruntime* zurÃ¼ck

  * Sobald ein Job aufwacht, erhÃ¤lt er den Minimum Wert im Baum (Liste aller laufende Jobs)
  * Â»StarvationÂ« wird vermieden
  * Nachteil: Jobs, die nur kurz schlafen, bekommen hierdurch keinen fairen Anteil   

### Abschluss

* Am Beispiel des CFS sieht man, dass die Wahl einer geeigneten Datenstruktur eine signifikante Auswirkung auf ein System haben kann 
* Deswegen macht es durchaus Sinn, sich mit dem Thema *Algorithmen und Datenstrukturen* in SEB3 auseinanderzusetzen

### Referenzen 

[1]	By Cburnett - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=1508398


## Hausaufgaben

### Einheit 1 (Git)

- Udacity Kurs zum Thema Git:Â [https://www.udacity.com/course/version-control-with-git--ud123]https://www.udacity.com/course/version-control-with-git--ud123
- 1x in GitLab (https://git.it.hs-heilbronn.de) anmelden
- C-Crashkurs durcharbeiten: https://github.com/aheil/hhn-c

### Einheit 2 (Prozess API)

- Bearbeiten Sie die Ãœbungsaufgaben zum Thema Process API aus dem OSTEP-Buch [https://pages.cs.wisc.edu/~remzi/OSTEP/cpu-api.pdf](https://pages.cs.wisc.edu/~remzi/OSTEP/cpu-api.pdf)
