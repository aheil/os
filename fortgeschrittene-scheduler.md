# Einheit 6: Fortgeschrittene Scheduler

### Lernziele

* Funktionsweise realer Scheduler **kennen lernen**

## I/O und Overlapping

* Wir haben zwei Typen von Schedulern kennen gelernt
  * SJF/STCF optimiert Turnaround-Zeiten, ist jedoch ungÃ¼nstig fÃ¼r Antwortzeiten
  * RR optimiert die Antwortzeit, ist aber ungÃ¼nstig fÃ¼r die Turnaround-Zeit
* Es gibt auf Basis des vorangehenden Abschnitts noch zwei Annahmen/Restriktionen, die Â»aufgelÃ¶stÂ« werden mÃ¼ssen
  4. Alle Jobs verwenden ausschlieÃŸlich die CPU
  5. Laufzeit eines jedes Jobs ist bekannt

**Input/Output**

* LÃ¶sen wir daher die nÃ¤chste Restriktion: Ab sofort kÃ¶nnen Jobs auch I/O-Operationen aufrufen
* Scheduler muss nun entscheiden wann eine I/O-Operation durchgefÃ¼hrt wird, da in der Zeit der laufende Prozess die CPU nicht nutzen kann und sich somit im Status Â»blockedÂ« befindet
* Scheduler kann demnach in dieser Zeit einen anderen Job laufen lassen
* Ist die I/O-Operation fertig (wird Ã¼ber Interrupt angezeigt), wird der zuvor geblockte Job wieder auf Â»readyÂ« gesetzt
* Ab jetzt kann er Job potentiell wieder la

**Overlapping**

* Schlechte Ressourcen-Nutzung

<figure><img src=".gitbook/assets/os.03.schechte_ressourcennutzung.png" alt=""><figcaption></figcaption></figure>

Bessere Ressourcen-Nutzung dank Overlapping

<figure><img src=".gitbook/assets/os.03.overlapping.png" alt=""><figcaption></figcaption></figure>

### Prozessdauer

**In Wirklichkeit haben wir kein Wissen Ã¼ber Prozessdauer**

* Als letzte Restriktion lÃ¶sen wir nun die Kenntnisse Ã¼ber die Prozesslaufzeit auf
* D.h. der Scheduler weiÃŸ nichts Ã¼ber die Restlaufzeit eines Prozesses
* Wie kann dann sinnvoll gescheduled werden?
* Zuletzt lassen wir daher die Annahme fallen, dass wir die Laufzeit eines Prozesses im Vorhinein wissen
* Wie kann ohne diese Kenntnisse ein Scheduler gebaut werden, er sowohl Antwortzeiten (z.B. fÃ¼r interaktive Anwendungen) als auch die Turnaround-Zeiten (d.h. ein Job mÃ¶glichst schnell fertig stellen) ohne Wissen Ã¼ber die Laufzeit eines Prozesses minimiert?

**LÃ¶sungsidee**: sog. Â»Multi-Level Feedback QueueÂ«-AnsÃ¤tze verwenden die nahe Vergangenheit, um die Zukunft vorauszusagen! ğŸ¤©

**Multi Level Feedback Queue (MLFQ)**

Grundlegende Regeln

* MLFQ hat mehrere Queues, jede mit einem PrioritÃ¤ts-Level
* Jobs mit hÃ¶herer PrioritÃ¤t laufen zuerst (=hÃ¶here Queue)
* Falls sich mehrere Jobs in der gleichen Queue befinden gilt:
  * Regel 1: `If Priority(A) > Priority(B), A runs (B doesnâ€˜t)`
  * Regel 2: `If Priority(A) == Priority(B), A & B run in Round Robin`
* Wie wird jedoch die PrioritÃ¤t fÃ¼r ein Job festgelegt?
  * PrioritÃ¤t nicht fix, sondern hÃ¤ngt vom **beobachteten Verhalten** des Jobs ab
* Wenn die ganze CPU-Zeit auf A und B verteilt wird, wie kommen dann aber C und D zum Zug?

<figure><img src=".gitbook/assets/os.04.mlfq.png" alt=""><figcaption></figcaption></figure>

Um die Fragen zu beantworten nÃ¤hern wir uns der LÃ¶sung schrittweisen:

#### 1. Versuch - PrioritÃ¤ten Ã¤ndern

* Workload Betrachtung: Mischung aus...
  * interaktiven Jobs, die kurz laufen, geben CPU schnell wieder frei und
  * langlaufende Jobs, die die CPU-intensiv in Anspruch nehmen, aber deren Antwortzeit Â»nicht relevantÂ« ist.
* ZusÃ¤tzliche Regeln:
  * Regel 3: Ein neu eintreffender Job erhÃ¤lt immer die hÃ¶chste PrioritÃ¤t (oberste Queue)
  * Regel 4a: Wenn ein Job die gesamte Zeitscheibe aufbraucht, wird seine PrioritÃ¤t herabgestuft (d.h. eine Queue nach unten geschoben)
  * Regel 4b: Wenn ein Job die CPU vor Ablauf der Zeitscheibe freigibt, bleibt er auf der gleichen PrioritÃ¤t (d.h. bleibt in der aktuellen Queue)

**Beispiel 1: Ein langlaufender Job**

* Job lÃ¤uft immer bis ans Ende der Time Slice
* Nach jeder Time Slice wird der Job heruntergestuft
* Am Ende lÃ¤uft der Job auf der niedrigsten PrioritÃ¤t

\


<figure><img src=".gitbook/assets/os.04.one_sad_job.png" alt=""><figcaption></figcaption></figure>

**Beispiel 2: Ein zusÃ¤tzlicher Â»KurzlÃ¤uferÂ«**

* Bei ğ‘‡=100 trifft ein zweiter, kurzlaufender Job ein
* MLFQ trifft immer die Annahme, dass ein neuer Job ein Â»KurzlÃ¤uferÂ« ist

<figure><img src=".gitbook/assets/os.04.kurzlaeufer.png" alt=""><figcaption></figcaption></figure>

**B**![](.gitbook/assets/os.04.io.png)**eispiel 3: ZusÃ¤tzliche I/O**

* Mischung aus I/O-intensivem und CPU-intensivem Job
* Nach Regel 4 bleibt der Job, der die CPU schnell freigibt, weil er z.B. auf die Tastatur wartet, hoch priorisiert
* Wer sieht denn das Problem?

Game the Scheduler

* Programm so schreiben, dass es kurz vor Ablauf der Zeitscheibe einen Dateizugriff ausfÃ¼hrt (die Datei selbst ist uns komplett egal)
* Programm bleibt hoch priorisiert, da Zeitscheibe nicht vollstÃ¤ndig aufgebraucht
* Machen wir das immer bei â‰ˆ 99% der Zeitscheibe, kÃ¶nnten wir die CPU 99% Ã¼bernehmen
* Langlaufende Jobs bleiben auf der Strecke (engl. starvation)
* Job A kommt nie mehr in eine bessere Queue, selbst wenn sich sein Verhalten Ã¤ndert

Wie kÃ¶nnten wir das besser machen?

<figure><img src=".gitbook/assets/os.04.game_the_scheduler.png" alt=""><figcaption></figcaption></figure>

**Versuch 2: Priority Boost**

* Neue Regel
  * Regel 5: Nach definierten Zeit _s_ werden alle Jobs wieder in die oberste Queue verschoben
* Regel 5 lÃ¶st zwei Probleme
  * Prozesse laufen nicht mehr Gefahr der Â»StarvationÂ«
  * Wenn ein Job Â»plÃ¶tzlichÂ« interaktiv wÃ¼rde, kann er entsprechend priorisiert werden (s. folgende Seiten)

**Voodoo Constant**

Spannende Frage: Wie lange sollte die Zeitspanne _s_ sein?

* Der Wert _s_ heiÃŸt nach John Ousterhout Â»Voodoo ConstantÂ«.
* FÃ¼r die Bestimmung sog. Voodoo-Konstanten benÃ¶tigt das System etwas Â»schwarze MagieÂ« zu deren Bestimmung
* Dilemma: Wenn _s_ zu groÃŸ gewÃ¤hlt wird, kÃ¶nnen CPU-intensive Jobs doch verhungern, ist sie zu klein gewÃ¤hlt bekommen interaktive Jobs nicht genÃ¼gend CPU
* Generell sollten Voodoo-Konstanten vermieden werden (Ousterhout's Law)

#### Versuch 3: Verbesserte BuchfÃ¼hrung

* Problem: Regel 4a und 4b ermÃ¶glichen immer noch, dass der Scheduler ausgespielt wird
* LÃ¶sungsidee: Eine verbesserte BuchfÃ¼hrung
* Merken wie viel Zeit ein Prozess in einer Queue verbracht hat
* Sobald ein Prozess kumuliert eine Zeitscheibe aufgebraucht hat, wandert er eine Queue nach unten
* Aus den Regeln 4a und 4b wird
  * Regel 4: Sobald ein Job seine gesamte Zeit auf einer PrioritÃ¤tsebene genutzte hat (ungeachtet dessen, wie viel Zeit er der CPU Â»zurÃ¼ck gibtÂ«), wird seine PrioritÃ¤t reduziert (d.h. er wandert eine Queue nach unten).

**Tuning und MLFQ Probleme**

* Wie sollte MLFQ priorisiert werden?
* Wie viele Queues
* Wie groÃŸ sollte die Zeitspanne (engl. time slice) pro Queue sein?
* Machen unterschiedliche Time Slices pro Queue Sinn?
* Wie oft findet Priority Boost statt?

**MLFQ Regeln**

* **R 1**: If Priority(A) > Priority(B), A runs (B doesnâ€™t)
* **R 2**: If Priority(A) = Priority(B), A & B run in round-robin fashion using the time slice (quantum length) of the given queue.
* **R 3**: When a job enters the system, it is placed at the highest priority (the topmost queue).
* **R 4**: Once a job uses up its time allotment at a given level (regardless of how many times it has given up the CPU), its priority is reduced (i.e., it moves down one queue).
* **R 5**: After some time period _s_, move all the jobs in the system to the topmost queue.\


**Wird MLFQ Ã¼berhaupt irgendwo verwendet?**

* Solaris
  * MLFQ _Time-Sharing Scheduling Class_ wird Ã¼ber eine Reihe von Tabellen konfiguriert
  * Diese kÃ¶nnen durch einen Admin angepasst werden ğŸ˜±
  * 60 Queues, mit langsam steigenden Time Slices von 20 ms bis zu 1 Sekunde
* FreeBSD
  * Scheduler nutzt Formel um PrioritÃ¤t eines Jobs zu berechnen
  * Wie viel CPU hat der Prozess schon verbraucht + wie ist der Verbrauch abgefallen (sog. Decay-Usage Algorithms)

## Lottery Scheduling

### Proportional / Fair Share Scheduler

Anstelle Turnaround-Zeiten zu optimieren, versuchen Fair Share Scheduler sicherzustellen, dass jeder Job einen gewissen Prozentsatz der CPU-Ressourcen erhÃ¤lt

* Beispiel: Lottery Scheduling
* Grundidee: Es werden Tickets vergeben, die wie in einer Lotterie gezogen werden
* Prozesse, die Ã¶fters laufen sollen, erhalten schlicht mehr Lotterieloseâ€¦

**Grundkonzept: Tickets represent your share**

* Grundlegendes Konzept: Es werden Tickets vergeben (entsprechen einem CPU Share)
* Beispiel:
  * Job A erhÃ¤lt 75% der Tickets (hier: Lose 0..74)
  * Job B erhÃ¤lt 25% der Tickets (hier: Lose 75..99)
  * Scheduler muss nun wissen, wie viele Lose es insgesamt gibt (hier: 100)
  * Gewinnerticket gibt an, welcher Prozess lÃ¤uft

\


**Lottery Scheduler - Ãœberlegungen**

* Statistische AnnÃ¤herung an gewÃ¼nschte Aufteilung
* Je lÃ¤nger die Jobs laufen, desto besser ist die AnnÃ¤herung
* Was ist bei einer Verteilung 99% zu 1%?
* Man benÃ¶tigt einen guten Zufallsgenerator
* Was macht man wenn ein neuer Job dazu kommt?

**Ticket WÃ¤hrung**

User mit mehreren Tickets, kann diese einer eigene Â»WÃ¤hrungÂ« zuordnen

* Beispiel
  * A und B haben je 100 Tickets
  * A hat zwei Jobs, A1 und A2, jeder Job bekommt 500 (von insg. 1.000) User Tickets in Aâ€˜s WÃ¤hrung
  * B hat 1 Job B1, dieser bekommt 10 von 10 (User Tickets) in Bâ€˜s WÃ¤hrung
  * System konvertiert Aâ€˜s Tickets pro Job zu je 50 Tickets in der SystemwÃ¤hrung
  * System konvertiert Bâ€˜s Ticktes zu 100 Tickets in SystemwÃ¤hrung



## **Linux Completely Fair Scheduler (CFS)**

* Problem: Scheduling kann bis zu 5% der CPU-Ressource ausmachen
* CFS fÃ¼hrt eine virtual runtime (_vruntime_) ein
* Jeder Prozess, der lÃ¤uft, sammelt _vruntime_ an Bei Scheduling-Entscheidung wÃ¤hlt der Scheduler den Prozess mit der geringsten vruntime aus

CFS: Wie oft sollte ein Prozess gewechselt werden?

* `sched_latency`
  * Time Slice Dauer, typischerweise 48ms
  * Wird durch Anzahl der Prozesse _n_ geteilt
  * Ergibt die Zeitscheibe pro Prozess
  * Somit ist die Zeitverteilung vollstÃ¤ndig fair
* `min_granularity`
  * Mindestdauer, typischerweise 6ms
  * Dieser Wert wird niemals unterschritten (Bsp. 10 Prozesse ergÃ¤be 4,8ms pro Prozess)

**CFS - Beispiel**

* CFS nutzt regelmÃ¤ÃŸige Timer Interrupts, der Scheduler kann Entscheidungen also immer nur zu fixen Zeitpunkten treffen
* Vier Jobs (A,B,C,D), wobei B, C und D kurz nach A eintreffen
* Nach der ersten Zeitscheibe wird einer der Jobs aus (B,C,D) gewÃ¤hlt da hier vruntime von B, C und D < vruntime von A
* Nach _t = 100_ sind C und D fertig, danach wird die vruntime zwischen A und B aufgeteilt

**CFS - Weighting / Niceness**

CFS ermÃ¶glicht die Angabe von PrioritÃ¤ten, damit Prozesse mehr CPU-Ressourcen erhalten kÃ¶nnen.

* In UNIX entspricht das dem Â»nice levelÂ«
* Kann zwischen -20 und + 19 gesetzt werden
* 0 ist Standardwert
* < 0 hÃ¶here Prio, > 0 kleinere Prio\


**CFS: Zeitscheibe berechnen**

* Gewichtungen erlauben es die Zeitscheibe pro Prozess zu berechnen:

$$
time\_sclice_k = \frac{weight_k}{\sum\limits_{i=0}^{n}weight_i}\cdot sched\_latency
$$

* Beispiel:
  * 2 Prozesse A (Prio=-5), B (Prio=0)
  * ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ´ = 3121, ğ‘¤ğ‘’ğ‘–ğ‘”â„ğ‘¡ğµ=1024
  * A erhÃ¤lt 36ms, B erhÃ¤lt 12ms



<figure><img src=".gitbook/assets/os.04.prio_to_weight (1).png" alt=""><figcaption></figcaption></figure>

**CFS: vruntime berechnen**

$$
vruntime_i = vruntime\cdot \frac{weight_0}{weight_i} \cdot runtime_i
$$

* Hinweis:
  * Gewichtung bleibt im VerhÃ¤ltnis gleich, wenn andere PrioritÃ¤ten gewÃ¤hlt werden
  * Annahme A hat 5 und B hat 10
  * A und B werden noch im selben VerhÃ¤ltnis wie zuvor gescheduled\


**CFS Prozesslisten**

\


* Problem: Bei mehreren hundert oder gar 1.000 Prozessen, wie wird der nÃ¤chste Prozess gefunden?
* Kurzes Gedankenspiel: Skalieren Listen? Hier mÃ¼ssten man immer aller linear durchsuchen, was in einem linearen Aufwand von ğ‘‚(ğ‘›) resultiert.
* LÃ¶sung: Geschickte Wahl der Datenstruktur:
  * CFS speichert Prozesse in Rot-Schwarz-BÃ¤umen (ausgeglichener Baum)
  * Algorithmen auf Rot-Schwarz-BÃ¤umen sind logarithmisch mit einem Aufwand von ğ‘‚(lğ‘œğ‘”ğ‘›)
* Deswegen: Algorithmen und Datenstrukturen

> Am Beispiel des CFS sieht man, dass die Wahl einer geeigneten Datenstruktur eine signifikante Auswirkung auf ein System haben kann. Deswegen macht es durchaus Sinn, sich mit dem Thema _Algorithmen und Datenstrukturen_ in SEB3 auseinanderzusetzen.

**CFS und I/O**

* Was passiert eigentlich wenn ein Prozess A permanent lÃ¤uft, weil B aufgrund einer I/O-Operation blockiert (z.B. 10s)?
* B wacht auf und hat die niedrigste vruntime (10s kleiner als bei A)
* B wÃ¼rde nun die CPU fÃ¼r 10s monopolisieren, Â»StarvationÂ« von A wÃ¤re potentiell mÃ¶glich
* LÃ¶sung: CFS setzt die _vruntime_ zurÃ¼ck
  * Sobald ein Job aufwacht, erhÃ¤lt er den Minimum Wert im Baum (Liste aller laufende Jobs)
  * Â»StarvationÂ« wird vermieden
  * Nachteil: Jobs, die nur kurz schlafen, bekommen hierdurch keinen fairen Anteil

## Hausaufgabe

\
Machen Sie sich mit dem Befehl `nice` (Linux) **und** `start` (Windows) vertraut

\
\
\
\
\
\


\
\


\
\


\




\
